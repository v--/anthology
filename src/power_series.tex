\section{Complex analysis}\label{subsec:complex_analysis}
\subsection{Power series}\label{subsec:power_series}

Here \( \K \) will refer to either \( \R \) or \( \C \).

\begin{definition}\label{def:convergent_series}
  When extending addition to a countable amount of terms, we need to impose some regularity conditions to avoid contradictions. The topologies of \( \R \) and \( \C \) are complete and allow us to define convergent and divergent series.

  A \Def{numeric series} or simply \Def{series} is an infinite sequence \( a_0, a_1, \ldots \in \K \), which we call \Def{terms}, usually written as
  \begin{equation}\label{def:convergent_series/series}
    \sum_{i=0}^\infty a_i.
  \end{equation}

  To each series, there corresponds its sequence of \Def{partial sums}
  \begin{equation*}
    S_n \coloneqq \sum_{i=0}^n a_i, n = 0, 1, 2, \ldots.
  \end{equation*}

  We can equivalently define a series as a sequence of partial sums and then recover the terms as
  \begin{equation*}
    a_i \coloneqq \begin{cases}
      S_0,           &i = 0, \\
      S_i - S_{i-1}, &i > 0
    \end{cases}
  \end{equation*}

  We say that the series \cref{def:convergent_series/series} \Def{converges} to a value \( a \) if \( \lim_{n \to \infty} S_n = a \) in the sense of \cref{thm:metric_topology_convergence}. The value \( a \) is called the \Def{sum} of the series.

  If a series does not converge, we say that it is \Def{divergent}.

  If the related series
  \begin{equation}\label{def:convergent_series/absolute_series}
    \sum_{i=0}^\infty \Abs{a_i}
  \end{equation}
  converges, we say that \cref{def:convergent_series/series} is \Def{absolutely convergent}.
\end{definition}

\begin{proposition}\label{thm:absolutely_convergent_series_is_convergent}
  An absolutely convergent series is convergent.
\end{proposition}
\begin{proof}
  Suppose that \cref{def:convergent_series/absolute_series} converges.

  By the triangle inequality, for each index \( n \) we have
  \begin{equation*}
    \Abs{\sum_{i=0}^n a_i} \leq \sum_{i=0}^n \Abs{a_i} \leq \sum_{i=0}^\infty \Abs{a_i}.
  \end{equation*}

  Thus the sequence \( \left\{ \Abs{\sum_{i=0}^{n} a_i} \right\}_{n=0}^\infty \) is a bounded (by \( \sum_{i=0}^\infty \Abs{a_i} \)) monotone sequence, which by \cref{thm:real_monotone_sequence_converges_iff_bounded} is convergent.

  Therefore the series \cref{def:convergent_series/series} is convergent.
\end{proof}

\begin{proposition}\label{thm:infinitary_triangle_inequality}
  For every series \cref{def:convergent_series/series} we have
  \begin{equation}\label{thm:infinitary_triangle_inequality/inequality}
    \Abs{\sum_{i=0}^\infty a_i} \leq \sum_{i=0}^\infty \Abs{a_i},
  \end{equation}
  where both limits are allowed to be infinite.
\end{proposition}
\begin{proof}
  If the series on the right diverges, the inequality is obviously true.

  Suppose that it is convergent. By \cref{thm:absolutely_convergent_series_is_convergent}, the limit
  \cref{def:convergent_series/series} exists.

  By the triangle inequality, for each index \( n \) we have
  \begin{equation*}
    \Abs{\sum_{i=0}^n a_i} \leq \sum_{i=0}^n \Abs{a_i}.
  \end{equation*}

  By \cref{thm:one_sided_squeeze_lemma}, since both sequences are convergent, we obtain \cref{thm:infinitary_triangle_inequality/inequality}.
\end{proof}

\begin{proposition}\label{thm:convergent_series_terms_vanish}
  The terms of the convergent series \cref{def:convergent_series/series} vanish as \( i \to \infty \), that is,
  \begin{equation*}
    \lim_{i \to \infty} a_i = 0.
  \end{equation*}
\end{proposition}
\begin{proof}
  Since the series is convergent, its sequence of partial sums converges, i.e. the partial sums get arbitrarily close to each other. Then
  \begin{equation*}
    \Abs{a_n} = \Abs{S_n - S_{n-1}} \to 0.
  \end{equation*}
\end{proof}

\begin{proposition}[Cauchy's convergence criterion]\label{thm:cauchy_series_convergence_criterion}\cite[3.22]{Rudin1991}
  The series \cref{def:convergent_series/series} converges if and only if for every \( \varepsilon > 0 \) there exists an index \( K \) such that
  \begin{equation*}
    m, n \geq K \implies \Abs{\sum_{k=m}^n a_k} < \varepsilon.
  \end{equation*}
\end{proposition}
\begin{proof}
  This is simply a restatement of \cref{thm:cauchys_convergence_criterion}.
\end{proof}

\begin{definition}\label{def:convergent_power_series}
  Let \( \K[[X]] \) be the space of power series defined in \cref{def:formal_power_series}.

  To each formal power series
  \begin{equation*}
    \sum_{k=0}^\infty a_k X^k
  \end{equation*}
  there corresponds a function, called a \Def{power series}
  \begin{equation}\label{def:convergent_power_series/series}
    p(x) \coloneqq \sum_{k=0}^\infty a_k x^k.
  \end{equation}

  We sometimes slightly generalize this notion slightly by using a \enquote{shift} by \( \alpha \in \K \): define the function
  \begin{equation}\label{def:convergent_power_series/shifted_series}
    p(x) \coloneqq \sum_{k=0}^\infty a_k (x - \alpha)^k.
  \end{equation}

  If the limit exists (as a numeric series\Tinyref{def:convergent_series}) for a certain \( x \in \K \), we say that the series \Def{converges} at \( x \).

  The series is no longer \enquote{formal} because it is now a proper function instead of an abstract algebraic object, although a power series may only be defined in a subset of \( \K \) (that is, a partial function\Tinyref{def:function/partial}).
\end{definition}

\begin{theorem}\label{thm:power_series_radius_of_convergence}
  For every power series \cref{def:convergent_power_series/series}, there exists a nonnegative extended real number \( r \in [0, +\infty] \), called its \Def{radius of convergence}, such that \cref{def:convergent_power_series/series} converges absolutely if \( \Abs{x} < r \) and diverges if \( \Abs{x} > r \).

  The behavior of the series is more complicated when \( \Abs{x} = r \) (unless \( r = 0 \), in which case the power series converges if and only if \( x = 0 \)).
\end{theorem}
\begin{proof}
  Define
  \begin{equation*}
    q \coloneqq \limsup_{n \to \infty} \sqrt[n]{\Abs{a_n}},
  \end{equation*}
  where we put \( q = +\infty \) if the limit does not exist. We have
  \begin{equation*}
    \limsup_{n \to \infty} \sqrt[n]{\Abs{x^n a_n}} = \Abs{x} q.
  \end{equation*}

  By \cref{thm:cauchys_root_test}, \cref{def:convergent_power_series/series} converges absolutely if \( \Abs{x} q < 1 \) and diverges if \( \Abs{x} q > 1 \).

  Thus \( r \coloneqq \tfrac 1 q \) is the desired radius of convergence.
\end{proof}

\begin{definition}\label{def:exponential_function}
  We define the \Def{exponential function}
  \begin{equation}\label{def:exponential_function/series}
    \exp(x) \coloneqq \sum_{k=0}^\infty \frac {x^k} {k!}.
  \end{equation}

  We define \Def{Euler's number} as
  \begin{equation*}
    e \coloneqq \exp(1) = \sum_{i=0}^k \frac 1 {k!}.
  \end{equation*}

  \Cref{thm:exponential_function_properties/interpolates_power} justifies the notation \( e^x = \exp(x) \).
\end{definition}

\begin{proposition}\label{thm:exponential_function_properties}
  The exponential function \( \exp(x) \) has the following basic properties:

  \begin{thmenum}
    \DItem{thm:exponential_function_properties/convergence} The radius of convergence\Tinyref{thm:power_series_radius_of_convergence} is infinite, that is, \( \exp(x) \) is defined for all \( x \in \C \).

    \DItem{thm:exponential_function_properties/interpolates_power} The notation \( \exp(x) \) is consistent with iterated multiplication as defined in \cref{def:semiring/dioid}, that is, \( \exp(n) = \underbrace{e \cdot \ldots \cdot e}_{n \text{times}} \).
  \end{thmenum}
\end{proposition}
\begin{proof}
  \begin{description}
    \RItem{thm:exponential_function_properties/convergence} By \cref{thm:power_series_radius_of_convergence}, the radius of convergence is \( \limsup_{k \to \infty} \sqrt[k]{k!} \). By \cref{thm:stirlings_approximation},
    \begin{equation*}
      \sqrt[k]{k!}
      =
      \sqrt[k]{\sqrt{2 \pi k} \left(\frac k e \right)^k \left(1 + \O \left(\frac 1 k \right) \right)}
      =
      \frac k e \sqrt[k]{\sqrt{2 \pi k} \left(1 + \O \left(\frac 1 k \right) \right)}
      \xrightarrow[k \to \infty]{} \infty.
    \end{equation*}

    Hence the radius of convergence of \( \exp(x) \) is infinite.
  \end{description}
\end{proof}
