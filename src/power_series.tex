\section{Complex analysis}\label{sec:complex_analysis}
\subsection{Power series}\label{subsec:power_series}

Here \( \K \) will refer to either \( \R \) or \( \C \).

\begin{definition}\label{def:convergent_series}
  When extending addition to a countable amount of terms, we need to impose some regularity conditions to avoid contradictions. The topologies of \( \R \) and \( \C \) are complete and allow us to define convergent and divergent series.

  A \Def{numeric series} or simply \Def{series} is an infinite sequence \( a_0, a_1, \ldots \in \K \), which we call \Def{terms}, usually written as
  \begin{equation}\label{def:convergent_series/series}
    \sum_{i=0}^\infty a_i.
  \end{equation}

  To each series, there corresponds its sequence of \Def{partial sums}
  \begin{equation*}
    S_n \coloneqq \sum_{i=0}^n a_i, n = 0, 1, 2, \ldots.
  \end{equation*}

  We can equivalently define a series as a sequence of partial sums and then recover the terms as
  \begin{equation*}
    a_i \coloneqq \begin{cases}
      S_0,           &i = 0, \\
      S_i - S_{i-1}, &i > 0
    \end{cases}
  \end{equation*}

  We say that the series \cref{def:convergent_series/series} \Def{converges} to a value \( a \) if \( \lim_{n \to \infty} S_n = a \) in the sense of \cref{thm:metric_topology_convergence}. The value \( a \) is called the \Def{sum} of the series.

  If a series does not converge, we say that it is \Def{divergent}.

  If the related series
  \begin{equation}\label{def:convergent_series/absolute_series}
    \sum_{i=0}^\infty \Abs{a_i}
  \end{equation}
  converges, we say that \cref{def:convergent_series/series} is \Def{absolutely convergent}.
\end{definition}

\begin{proposition}\label{thm:absolutely_convergent_series_is_convergent}
  An absolutely convergent series is convergent.
\end{proposition}
\begin{proof}
  Suppose that \cref{def:convergent_series/absolute_series} converges.

  By the triangle inequality, for each index \( n \) we have
  \begin{equation*}
    \Abs{\sum_{i=0}^n a_i} \leq \sum_{i=0}^n \Abs{a_i} \leq \sum_{i=0}^\infty \Abs{a_i}.
  \end{equation*}

  Thus the sequence \( \left\{ \Abs{\sum_{i=0}^{n} a_i} \right\}_{n=0}^\infty \) is a bounded (by \( \sum_{i=0}^\infty \Abs{a_i} \)) monotone sequence, which by \cref{thm:real_monotone_sequence_converges_iff_bounded} is convergent.

  Therefore the series \cref{def:convergent_series/series} is convergent.
\end{proof}

\begin{corollary}
  Convergence of the complex series \cref{def:convergent_series/series} can be established using the convergence of the nonnegative series \cref{def:convergent_series/absolute_series}.

  The convergence of the latter can be established using techniques in \cref{subsec:real_series} like \fullref{thm:cauchys_root_test} or \fullref{thm:dalamberts_ratio_test}.
\end{corollary}

\begin{proposition}\label{thm:infinitary_triangle_inequality}
  For every series \cref{def:convergent_series/series} we have
  \begin{equation}\label{thm:infinitary_triangle_inequality/inequality}
    \Abs{\sum_{i=0}^\infty a_i} \leq \sum_{i=0}^\infty \Abs{a_i},
  \end{equation}
  where both limits are allowed to be infinite.
\end{proposition}
\begin{proof}
  If the series on the right diverges, the inequality is obviously true.

  Suppose that it is convergent. By \cref{thm:absolutely_convergent_series_is_convergent}, the limit
  \cref{def:convergent_series/series} exists.

  By the triangle inequality, for each index \( n \) we have
  \begin{equation*}
    \Abs{\sum_{i=0}^n a_i} \leq \sum_{i=0}^n \Abs{a_i}.
  \end{equation*}

  By \cref{thm:one_sided_squeeze_lemma}, since both sequences are convergent, we obtain \cref{thm:infinitary_triangle_inequality/inequality}.
\end{proof}

\begin{proposition}\label{thm:convergent_series_terms_vanish}
  The terms of the convergent series \cref{def:convergent_series/series} vanish as \( i \to \infty \), that is,
  \begin{equation*}
    \lim_{i \to \infty} a_i = 0.
  \end{equation*}
\end{proposition}
\begin{proof}
  Since the series is convergent, its sequence of partial sums converges, i.e. the partial sums get arbitrarily close to each other. Then
  \begin{equation*}
    \Abs{a_n} = \Abs{S_n - S_{n-1}} \to 0.
  \end{equation*}
\end{proof}

\begin{proposition}[Cauchy's convergence criterion]\label{thm:cauchy_series_convergence_criterion}\cite[3.22]{Rudin1991}
  The series \cref{def:convergent_series/series} converges if and only if for every \( \varepsilon > 0 \) there exists an index \( K \) such that
  \begin{equation*}
    m, n \geq K \implies \Abs{\sum_{k=m}^n a_k} < \varepsilon.
  \end{equation*}
\end{proposition}
\begin{proof}
  This is simply a restatement of \cref{thm:cauchys_convergence_criterion}.
\end{proof}

\begin{definition}\label{def:convergent_power_series}
  Let \( \K[[X]] \) be the space of power series defined in \cref{def:formal_power_series}.

  To each formal power series
  \begin{equation*}
    \sum_{k=0}^\infty a_k X^k
  \end{equation*}
  there corresponds a function, called a \Def{power series}
  \begin{equation}\label{def:convergent_power_series/series}
    p(x) \coloneqq \sum_{k=0}^\infty a_k x^k.
  \end{equation}

  We sometimes slightly generalize this notion slightly by using a \enquote{shift} by \( \alpha \in \K \): define the function
  \begin{equation}\label{def:convergent_power_series/shifted_series}
    p(x) \coloneqq \sum_{k=0}^\infty a_k (x - \alpha)^k.
  \end{equation}

  If the limit exists (as a numeric series\Tinyref{def:convergent_series}) for a certain \( x \in \K \), we say that the series \Def{converges} at \( x \).

  The series is no longer \enquote{formal} because it is now a proper function instead of an abstract algebraic object, although a power series may only be defined in a subset of \( \K \) (that is, a partial function\Tinyref{def:function/partial}).
\end{definition}

\begin{theorem}\label{thm:power_series_radius_of_convergence}
  For every power series \cref{def:convergent_power_series/series}, there exists a nonnegative extended real number \( r \in [0, +\infty] \), called its \Def{radius of convergence}, such that \cref{def:convergent_power_series/series} converges absolutely if \( \Abs{x} < r \) and diverges if \( \Abs{x} > r \).

  The behavior of the series is more complicated when \( \Abs{x} = r \) (unless \( r = 0 \), in which case the power series converges if and only if \( x = 0 \)).
\end{theorem}
\begin{proof}
  Define
  \begin{equation*}
    q \coloneqq \limsup_{n \to \infty} \sqrt[n]{\Abs{a_n}},
  \end{equation*}
  where we put \( q = +\infty \) if the limit does not exist. We have
  \begin{equation*}
    \limsup_{n \to \infty} \sqrt[n]{\Abs{x^n a_n}} = \Abs{x} q.
  \end{equation*}

  By \cref{thm:cauchys_root_test}, \cref{def:convergent_power_series/series} converges absolutely if \( \Abs{z} q < 1 \) and diverges if \( \Abs{z} q > 1 \).

  Thus \( r \coloneqq \tfrac 1 q \) is the desired radius of convergence.

  Note that we may also use \cref{thm:dalamberts_ratio_test} for finding the same radius of convergence by \cref{remark:nonnegative_series_convergence_test_equivalence}.
\end{proof}

\begin{proposition}\label{thm:power_series_parity}
  Power series of the form
  \begin{equation}\label{thm:power_series_parity/odd}
    f_o(z) \coloneqq \sum_{m \text{ is odd}} a_m z^m = \sum_{k=0}^\infty a_{2k+1} z^{2k+1}
  \end{equation}
  are odd functions\Tinyref{def:function_pairity} and power series of the form
  \begin{equation}\label{thm:power_series_parity/even}
    f_e(z) \coloneqq \sum_{m \text{ is even}} a_m z^m = \sum_{k=0}^\infty a_{2k} z^{2k}
  \end{equation}
  are even function.
\end{proposition}
\begin{proof}
  If \cref{thm:power_series_parity/odd} converges for \( z \in \C \),
  \begin{equation*}
    f_o(-z)
    =
    \sum_{k=0}^\infty a_{2k+1} (-z)^{2k+1}
    =
    \sum_{k=0}^\infty a_{2k+1} (-1)^{2k+1} z^{2k+1}
    =
    - \sum_{k=0}^\infty a_{2k+1} z^{2k+1}
    =
    - f_o(z).
  \end{equation*}

  Analogously, since \( (-1)^{2k} = 1 \), we have \( f_e(-z) = f_e(z) \).
\end{proof}

\begin{definition}\label{def:exponential_function}
  We define the \Def{exponential function}
  \begin{equation}\label{def:exponential_function/series}
    \exp(z) \coloneqq \sum_{k=0}^\infty \frac {z^k} {k!}.
  \end{equation}

  We define \Def{Euler's number} as
  \begin{equation*}
    e \coloneqq \exp(1) = \sum_{i=0}^k \frac 1 {k!}.
  \end{equation*}

  \Cref{thm:exponential_function_properties/interpolates_power} justifies the notation \( e^z = \exp(z) \).
\end{definition}
\begin{proof}
  We will show that \( \exp(z) \) converges everywhere. By \cref{thm:power_series_radius_of_convergence}, the radius of convergence is
  \begin{equation*}
    \limsup_{k \to \infty} \frac {k!} {(k-1)!}
    =
    \limsup_{k \to \infty} k
    =
    +\infty
  \end{equation*}

  Hence the radius of convergence of \( \exp(x) \) is infinite.
\end{proof}

\begin{definition}\label{def:trigonometric_functions}
  We define the following \Def{trigonometric functions}:

  \begin{defenum}
    \DItem{def:trigonometric_functions/sine} We define the \Def{sine} function as
    \begin{equation*}
      \sin(z)
      \coloneqq
      -i \sum_{m \text{ is odd}}^\infty \frac {i^m z^m} {m!}
      =
      -i \sum_{k=0}^\infty \frac {i^{2k+1} z^{2k+1}} {(2k + 1)!}
      =
      \sum_{k=0}^\infty \frac {i^{2k} z^{2k+1}} {(2k + 1)!}
    \end{equation*}

    By \cref{thm:power_series_parity}, \( \sin(z) \) is an odd function.

    \DItem{def:trigonometric_functions/cosine} We define the \Def{cosine} function as
    \begin{equation*}
      \cos(z)
      \coloneqq
      \sum_{m \text{ is even}}^\infty \frac {i^m z^m} {m!}
      =
      \sum_{k=0}^\infty \frac {i^{2k} z^{2k}} {(2k)!}.
    \end{equation*}

    By \cref{thm:power_series_parity}, \( \cos(z) \) is an even function.
  \end{defenum}

  Comparing these definitions with \cref{def:exponential_function}, we obtain \Def{Euler's formula}
  \begin{equation}\label{def:trigonometric_functions/eulers_formula}
    \exp(iz) = \cos(z) + i \sin(z),
  \end{equation}
  thus both \( \sin(z) \) and \( \cos(z) \) converge everywhere in \( \C \).

  From \cref{def:trigonometric_functions/eulers_formula} it also follows that
  \begin{align*}
    \sin(z) &= \Re(\exp(iz)) \\
    \cos(z) &= \Im(\exp(iz))
  \end{align*}
\end{definition}

\begin{proposition}[Pythagorean identity]\label{thm:pythagorean_identity}
  For \( t \in \R \),
  \begin{equation*}
    \sin(t)^2 + \cos(t)^2 = 1.
  \end{equation*}
\end{proposition}
\begin{proof}
  We use Cauchy multiplication for
  \begin{align*}
    \sin(t)^2
    &=
    \sin(t) \cdot \sin(t)
    = \\ &=
    (-i \cdot -i) \left( \sum_{k=0}^\infty \frac {i^{2k+1} z^{2k+1}} {(2k+1)!} \right) \left( \sum_{k=0}^\infty \frac {i^{2k+1} z^{2k+1}} {(2k+1)!} \right)
    = \\ &=
    -\sum_{k=0}^\infty \sum_{m=0}^k \frac {i^{2m+1} z^{2m+1}} {(2m+1)!} \frac {i^{2(k-m)+1} z^{2(k-m)+1}} {(2(k-m)+1)!}
    = \\ &=
    -\sum_{k=0}^\infty \frac {i^{2k+2} z^{2k+2}} {(2k+2)!} \sum_{m=0}^k \binom {2k+2} {2m+1}
    = \\ &=
    -\sum_{k=1}^\infty \frac {i^{2k} z^{2k}} {(2k)!} \sum_{m=0}^{k-1} \binom {2k} {2m+1}
  \end{align*}
  and for
  \begin{align*}
    \cos(t)^2
    &=
    \cos(t) \cdot \cos(t)
    = \\ &=
    \left( \sum_{k=0}^\infty \frac {i^{2k} z^{2k}} {(2k)!} \right) \left( \sum_{k=0}^\infty \frac {i^{2k} z^{2k}} {(2k)!} \right)
    = \\ &=
    \sum_{k=0}^\infty \sum_{m=0}^k \frac {i^{2m} z^{2m}} {(2m)!} \frac {i^{2(k-m)} z^{2(k-m)}} {(2(k-m))!}
    = \\ &=
    \sum_{k=0}^\infty \frac {i^{2k} z^{2k}} {(2k)!} \sum_{m=0}^k \binom {2k} {2m}
  \end{align*}

  For the sum we obtain
  \begin{align*}
    \sin(t)^2 + \cos(t)^2
    &=
    1 + \sum_{k=1}^\infty \frac {i^{2k} z^{2k}} {(2k)!} \left[ \sum_{m=0}^{k-1} \binom {2k} {2m+1} - \sum_{m=0}^k \binom {2k} {2m} \right]
    = \\ &=
    1 + \sum_{k=1}^\infty \frac {i^{2k} z^{2k}} {(2k)!} \sum_{m=0}^k (-1)^m \binom {2k} m
    = \\ &=
    1 + \sum_{k=1}^\infty \frac {i^{2k} z^{2k}} {(2k)!} \underbrace{(1 - 1)^k}_0
    =
    1.
  \end{align*}
\end{proof}

\begin{proposition}\label{thm:exponential_function_properties}
  The exponential function \( \exp(z) \) has the following basic properties:

  \begin{thmenum}
    \DItem{thm:exponential_function_properties/homomorphism} \( \exp(x + y) = \exp(x) \exp(y) \). Stated in another way, \( \exp \) is a homomorphism from the additive group of \( \C \) to the multiplicative group.

    \DItem{thm:exponential_function_properties/interpolates_power} The notation \( \exp(x) \) is consistent with iterated multiplication as defined in \cref{def:semiring/dioid}, that is, \( \exp(n) = \underbrace{e \cdot \ldots \cdot e}_{n \text{times}} \) and for positive integers \( n \), \( \exp(n) =  \) and \( \exp(-n) =\tfrac 1 {\exp(n)} \).

    \DItem{thm:exponential_function_properties/negative_power}
    \begin{equation*}
      \exp(z) = \frac 1 {\exp(-z)}.
    \end{equation*}

    \DItem{thm:exponential_function_properties/real_positive} For real \( t \), \( e^t \) is a positive real number.

    \DItem{thm:exponential_function_properties/conjugate} \( \Ol{\exp(z)} = \exp(\Ol{z}) \).

    \DItem{thm:exponential_function_properties/unit_circle} The function \( t \mapsto \exp(it) \) is a bijection between the half-open interval \( [0, 2\pi) \) and the unit circle in \( \C \).

    \DItem{thm:exponential_function_properties/real_bijective} \( t \mapsto \exp(t) \) is a bijection from \( \R \) to \( [0, \infty) \).

    \DItem{thm:exponential_function_properties/unit_disk} \( \exp(z) \) is a bijection between the strip \( S \coloneqq \{ a + bi \colon 0 \leq b < 2\pi \} \) and the unit disk in \( \C \).

    \DItem{thm:exponential_function_properties/periodic} \( \exp(z) \) is \( 2\pi \)-periodic\Tinyref{def:periodic_function}.

    \DItem{thm:exponential_function_properties/compound_interest} For nonnegative real \( t \geq 0 \) we have
    \begin{equation*}
      \exp(t) = \lim_{n \to \infty} \left(1 + \frac t n \right)^n
    \end{equation*}
  \end{thmenum}
\end{proposition}
\begin{proof}
  \RItem{thm:exponential_function_properties/homomorphism} The Cauchy product of \( \exp(x) \) and \( \exp(y) \) is
  \begin{align*}
    \exp(x) \exp(y)
    &=
    \left( \sum_{k=0}^\infty \frac {x^k} {k!} \right) \left( \sum_{k=0}^\infty \frac {y^k} {k!} \right)
    = \\ &=
    \sum_{k=0}^\infty \sum_{m=0}^k \frac {x^m} {m!} \frac {x^{k-m}} {(k-m)!}
    = \\ &=
    \sum_{k=0}^\infty \frac 1 {k!} \sum_{m=0}^k \binom{k}{m} x^m y^{k-m}
    \overset {\ref{thm:binomial_theorem}} = \\ &=
    \sum_{k=0}^\infty \frac {(x + y)^k} {k!}
    =
    \exp(x + y).
  \end{align*}

  \RItem{thm:exponential_function_properties/interpolates_power} We use induction on \( n \) to prove \( \exp(n) = e^n \). The case \( \exp(0) = 1 \) is obvious. If we assume that \( \exp(n) = e^n \), by \cref{thm:exponential_function_properties/homomorphism}, we have
  \begin{equation*}
    \exp(n + 1)
    =
    \exp(n) \exp(1)
    =
    e^n \cdot e
    =
    e^{n+1}.
  \end{equation*}

  Note that this works for negative \( n \) too.

  \RItem{thm:exponential_function_properties/negative_power} Note that
  \begin{equation*}
    1 = \exp(0) = \exp(z - z) = \exp(z) \exp(-z),
  \end{equation*}
  hence
  \begin{equation*}
    \exp(-z) = \frac 1 {\exp(z)}.
  \end{equation*}

  \RItem{thm:exponential_function_properties/real_positive} For \( t > 0 \), the following
  \begin{equation*}
    \exp(t) = \sum_{k=0}^\infty \frac {t^k} {k!}
  \end{equation*}
  is a series of positive real numbers. To see its convergence, we apply \fullref{thm:dalamberts_ratio_test}:
  \begin{equation*}
    \frac {t^k} {k!} \cdot \frac {(k-1)!} {t^{k-1}}
    =
    \frac t k
    \xrightarrow[k \to \infty]{} 0.
  \end{equation*}

  Thus \( \exp(t) \) is a nonnegative real number. Furthermore, since the sequence of partial sums is monotone, \( \exp(t) \) cannot be zero. Hence for \( t > 0 \), we have \( \exp(t) > 0 \).

  Notice that \( \exp(t) \exp(-t) > 0 \), hence if \( \exp(t) > 0 \), then \( \exp(-t) > 0 \).

  \RItem{thm:exponential_function_properties/conjugate} By \cref{def:trigonometric_functions/eulers_formula},
  \begin{align*}
    \Ol{\exp(a + bi)}
    &\overset {\ref{thm:exponential_function_properties/homomorphism}} =
    \Ol{\exp(a) \exp(bi)}
    \overset {\ref{thm:exponential_function_properties/real_positive}} = \\ &=
    \exp(a) \Ol{(\cos(b) + i\sin(b))}
    = \\ &=
    \exp(a) (\cos(b) - i\sin(b))
    \overset {\ref{thm:power_series_parity}} = \\ &=
    \exp(a) (\cos(-b) + i\sin(-b))
    = \\ &=
    \exp(a) \exp(-bi)
    = \\ &=
    \exp(a - bi)
    = \\ &=
    \exp(\Ol{a + bi}).
  \end{align*}

  \RItem{thm:exponential_function_properties/periodic} By \cref{def:pi},
  \begin{equation*}
    \exp(x + 2\pi i) = \exp(x) \exp(2 \pi i) = \exp(x).
  \end{equation*}

  Furthermore, this is also the minimal period because of the infimum in \cref{def:pi}.

  \RItem{thm:exponential_function_properties/unit_circle} For \( t \in \R \) we have
  \begin{equation*}
    \Abs{\exp(it)}
    =
    \Abs{\cos(t) + i\sin(t)}
    =
    \sqrt{\cos(t)^2 + \sin(t)^2}
    \overset {\ref{thm:pythagorean_identity}} =
    1
  \end{equation*}
  by \fullref{thm:pythagorean_identity}.

  Furthermore, if \( r \) is another real number,
  \begin{equation}
    \exp(ir)
    =
    \exp(i(t + (r - t)))
    =
    \exp(it) \exp(i(r - t)).
  \end{equation}

  It follows that \( \exp(ir) \neq \exp(it) \) if and only if \( \exp(i(r - t)) \neq 0 \). If \( t, r \in [0, 2\pi) \) and \( t \neq r \), this is satisfied.

  Hence \( t \mapsto \exp(it) \) is indeed an injection of \( [0, 2\pi) \) into the unit circle of \( \C \). It is also a surjection because of the intermediate value theorem.

  \RItem{thm:exponential_function_properties/real_bijective} First, assume\LEM that \( e^t \) is not injective on \( \R \). Then there exist \( t, r \in \R \), \( t \neq r \), such that \( e^t = e^r \). By \cref{thm:exponential_function_properties/real_positive}, both are positive real numbers. In particular, we can divide by \( e^t \) to obtain
  \begin{equation*}
    1
    =
    \frac {e^r} {e^t}
    \overset {\ref{thm:exponential_function_properties/negative_power}} =
    =
    e^r e^{-t}
    \overset {\ref{thm:exponential_function_properties/homomorphism}} =
    e^{r - t}.
  \end{equation*}

  We know that \( e^0 = 1 \) from \cref{thm:exponential_function_properties/interpolates_power}. Thus it is enough to show that \( e^t = 1 \) if and only if \( t = 0 \).

  Assume\LEM that \( e^t = 1 \) holds for some \( t > 0 \). The partial sums are monotonely increasing so in order for them to converge to \( 1 \), for any fixed index \( n \) we must have
  \begin{align*}
    0 &\leq \sum_{k=0}^n \frac {t^k} {k!} = 1 + \sum_{k=1}^n \frac {t^k} {k!} \leq 1,\\
    -1 &\leq \sum_{k=1}^n \frac {t^k} {k!} \leq 0.
  \end{align*}

  But \( \sum_{k=1}^n \frac {t^k} {k!} > 0 \) because \( t > 0 \). The obtained contradiction proves that \( e^t \neq 1 \) for positive \( t \).

  For negative \( t \), note that
  \begin{equation*}
    e^t e^{-t} = 1.
  \end{equation*}

  Since \( -t \) is positive, \( e^{-t} \neq 1 \) and hence \( e^t \neq 1 \).

  Therefore the function \( t \mapsto e^t \) is injective on \( \R \). It is also surjective onto \( \R^{>0} \) because of the intermediate value theorem.

  \RItem{thm:exponential_function_properties/unit_disk} Fix \( a + bi \in H \), that is, \( b \in [0, 2\pi) \). By \cref{thm:exponential_function_properties/homomorphism},
  \begin{equation*}
    e^{a + bi} = e^a e^{bi}.
  \end{equation*}

  By \cref{thm:exponential_function_properties/unit_circle}, \( b \mapsto e^{bi} \) is injective for \( b \in [0, 2\pi) \) and by \cref{thm:exponential_function_properties/real_bijective}, \( a \mapsto e^a \) is injective on \( \R \). It follows that their product is also injective.

  \RItem{thm:exponential_function_properties/compound_interest}\cite[3.31]{Rudin1991} By \fullref{thm:binomial_theorem},
  \begin{align*}
    \left(1 + \frac t n \right)^n
    &=
    \sum_{k=0}^n \binom{n}{k} \left(\frac t n\right)^k 1^{n-k}
    = \\ &=
    \sum_{k=0}^n \frac {n!} {(n-k)! k!} \frac {t^k} {n^k}
    = \\ &=
    \sum_{k=0}^n \frac {n!} {(n-k)! n^k} \frac {t^k} {k!}
    = \\ &=
    \sum_{k=0}^n \left[ \prod_{j=1}^k \left(1 - \frac {k+j} n \right) \right] \frac {t^k} {k!}.
  \end{align*}

  Fix an index \( m \). Since the series is nonnegative, there exists an index \( N \) such that for \( n \geq N \)
  \begin{equation*}
    \sum_{k=0}^m \frac {t^k} {k!}
    \leq
    \sum_{k=0}^n \left[ \prod_{j=1}^k \left(1 - \frac {k+j} n \right) \right] \frac {t^k} {k!}.
  \end{equation*}

  Note that
  \begin{equation*}
    \left[ \prod_{j=1}^k \left(1 - \frac {k+j} n \right) \right] \frac {t^k} {k!}
    \leq
    \frac {t^k} {k!},
  \end{equation*}
  hence
  \begin{equation*}
    \sum_{k=0}^m \frac {t^k} {k!}
    \leq
    \sum_{k=0}^n \left[ \prod_{j=1}^k \left(1 - \frac {k+j} n \right) \right] \frac {t^k} {k!}
    \leq
    \sum_{k=0}^n \frac {t^k} {k!}.
  \end{equation*}

  By \fullref{thm:squeeze_lemma},
  \begin{equation*}
    \lim_{n \to \infty} \left(1 + \frac t n \right)^n
    =
    \lim_{n \to \infty} \sum_{k=0}^n \frac {t^k} {k!}
    =
    \exp(t).
  \end{equation*}
\end{proof}

\begin{corollary}\label{thm:trigonometric_function_properties}
  \mbox{}
  \begin{thmenum}
    \DItem{thm:trigonometric_function_properties/period} Both \( \sin \) and \( \cos \) are periodic with base period \( 2\pi \).

    \DItem{thm:trigonometric_function_properties/sine_characterization}
    \begin{equation*}
       \sin(x) = \Re(e^x) = \frac {e^{ix} - e^{-ix}} {2i}
    \end{equation*}

    \DItem{thm:trigonometric_function_properties/cosine_characterization}
    \begin{equation*}
       \cos(x) = \Im(e^x) = \frac {e^{ix} + e^{-ix}} 2
    \end{equation*}
  \end{thmenum}
\end{corollary}

\begin{definition}\label{def:logarithm}

\end{definition}

\begin{definition}\label{def:power_function}
  We define the power function
  \begin{align*}
    &(-)^{-}: \K \times \K \to \K \\
    &x^y \coloneqq e^{y \log x}.
  \end{align*}
\end{definition}

\begin{definition}\label{def:hyperbolic_trigonometric_functions}
  In analogy with \cref{thm:trigonometric_function_properties/sine_characterization} and \cref{thm:trigonometric_function_properties/cosine_characterization}, we define \Def{hyperbolic trigonometric functions}.

  \begin{defenum}
    \DItem{def:hyperbolic_trigonometric_functions/sine} We define the \Def{hyperbolic sine} function as
    \begin{equation*}
      \sinh(x) \coloneqq - \frac {e^x - e^{-x}} 2 \\
    \end{equation*}

    \DItem{def:hyperbolic_trigonometric_functions/cosine} We define the \Def{hyperbolic cosine} function as
    \begin{equation*}
      \cosh(x) \coloneqq \frac {e^x + e^{-x}} 2
    \end{equation*}
  \end{defenum}

  See \cref{remark:hyperbolic_trigonometric_functions} for a justification.
\end{definition}
