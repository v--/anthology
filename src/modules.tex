\subsection{Modules}\label{subsec:modules}

\begin{definition}\label{def:left_module}
  Let \( R \) be a dioid\Tinyref{def:semiring/dioid} and \( M \) be an abelian group. Analogously to \cref{def:left_group_action}, we say that \( M \) is a left \( R \)-\Def{module} if it has some additional structure, which can be defined equivalently as
  \begin{defenum}
    \DItem{def:left_module/homomorphism} a dioid homomorphism from \( R \) to the endomorphism ring\Tinyref{def:endomorphism_dioid} \( \End(M) \)

    \DItem{def:left_module/multiplication}\cite[374]{Knapp2016BAlg} an associative \Tinyref{def:algebraic_theory/associativity} and unital\Tinyref{def:algebraic_theory/identity} operation\Tinyref{remark:left_group_actions_as_algebraic_structures} \( \cdot: R \times M \to M \), written using juxtaposition.

    We require that \( \cdot \) is associative, distributive\Tinyref{def:algebraic_theory/distributivity} over \( + \), and compatible with the identity in \( R \). Explicitly, the following are satisfied for \( x, y \in M \) and \( s, t \in R \):
    \begin{description}
      \DItem{def:left_module/associativity}[associativity] \( s \cdot (t \cdot x) = (s t) \cdot x \).
      \DItem{def:left_module/scalar_distributivity}[scalar distributivity] \( (s + t) \cdot x = s \cdot x + t \cdot x \).
      \DItem{def:left_module/vector_distributivity}[vector distributivity] \( t \cdot (x + y) = t \cdot x + t \cdot y \).
      \DItem{def:left_module/identity}[identity] \( 1_R \cdot x = x \).
    \end{description}
  \end{defenum}

  In analogy with vector spaces\Tinyref{def:vector_space}, we call elements of \( R \) scalars and elements of \( M \) vectors. See \cref{def:vector_space}.

  We denote the category of modules over \( R \) by \( \Cat{Mod}_R \).
\end{definition}
\begin{proof}
  \Implies[def:left_module/homomorphism][def:left_module/multiplication] Let \( \tau: R \to \End(M) \) be a ring homomorphism. Define the operation
  \begin{align*}
    &\cdot: R \times M \to M \\
    &\cdot(r, m) \coloneqq \tau(r)(m).
  \end{align*}

  Let \( x, y \in M \) and \( s, t \in R \). From the fact that \( \tau \) is a ring homomorphism, we have
  \begin{description}
    \RItem{def:left_module/associativity}
    \begin{equation*}
      s \cdot (t \cdot x)
      =
      \tau(s)(\tau(t)(x))
      =
      (\tau(s) \circ \tau(t))(x)
      =
      \tau(st)(x).
    \end{equation*}

    \RItem{def:left_module/scalar_distributivity}
    \begin{equation*}
      (s + t) \cdot x
      =
      \tau(s + t)(x)
      =
      \tau(s)(x) + \tau(t)(x)
      =
      s \cdot x + t \cdot x.
    \end{equation*}

    \RItem{def:left_module/vector_distributivity}
    \begin{equation*}
      t \cdot (x + y)
      =
      \tau(t)(x + y).
    \end{equation*}

    Now since \( \tau(t) \) is a group endomorphism, we have \( \tau(t)(x + y) = \tau(t)(x) + \tau(t)(y) \). Thus
    \begin{equation*}
      t \cdot (x + y)
      =
      t \cdot x + t \cdot y.
    \end{equation*}

    \RItem{def:left_module/identity}
    \begin{equation*}
      1_R \cdot x
      =
      \tau(1_R)(x)
      =
      \Id(x)
      =
      x.
    \end{equation*}
  \end{description}

  \Implies[def:left_module/multiplication][def:left_module/homomorphism] Let \( \cdot: R \times M \to M \) be a left scalar multiplication operation. We define
  \begin{align*}
    &\tau: R \to \End(M) \\
    &\tau(t) \coloneqq (x \mapsto t \cdot x).
  \end{align*}

  This function is well defined since for each \( t \in R \), the function \( \tau(t) \) is an abelian group homomorphism (due to \ref{def:left_module/associativity}).

  \( \tau \) is a ring homomorphism because
  \begin{itemize}
    \item it preserves addition:
    \begin{equation*}
      \tau(s + t)
      =
      (x \mapsto (s + t) \cdot x)
      =
      (x \mapsto s \cdot x + t \cdot x)
      =
      \tau(s) + \tau(t).
    \end{equation*}

    \item it preserves multiplication:
    \begin{equation*}
      \tau(st)
      =
      (x \mapsto (st) \cdot x)
      =
      (x \mapsto (s \cdot (t \cdot x)))
      =
      \tau(s) \circ \tau(t).
    \end{equation*}

    \item it preserves identities:
    \begin{equation*}
      \tau(1_R)
      =
      \Id,
    \end{equation*}
    which is the multiplicative unit in \( \End(M) \).
  \end{itemize}
\end{proof}

\begin{definition}\label{def:right_module}
  We say that \( \tau: R \to \End(A) \) is a \Def{right \( R \)-module} if the same function is a left module\Tinyref{def:left_module} on the opposite ring\Tinyref{def:opposite_ring} \( R^{-1} \).
\end{definition}

\begin{definition}\label{def:bimodule}
  An abelian group \( M \) that is both a left \( L \)-module and right \( R \)-module is called an \( L, R \)-\Def{bimodule} if \( l \in L, r \in R \) and \( x \in M \) implies
  \begin{equation*}
    (lx)r = l(xr).
  \end{equation*}
\end{definition}

\begin{proposition}\label{def:left_module_properties}
  Any left \( R \)-module \( M \) has the following basic properties:
  \begin{thmenum}
    \DItem{def:left_module_properties/ring_zero_is_absorbing} Multiplication by \( 0_R \) is absorbing\Tinyref{def:algebraic_theory/absorbing_element}, that is, \( 0_R x = 0_M \) for any \( x \in M \).

    \DItem{def:left_module_properties/module_zero_is_absorbing} Multiplication by \( 0_M \) is absorbing, that is, \( t 0_M = 0_M \) for any \( t \in R \).
  \end{thmenum}
\end{proposition}
\begin{proof}\mbox{}
  \begin{itemize}
    \RItem{def:left_module_properties/ring_zero_is_absorbing} For any \( x \in M \) we have that \( 0_R x = (0_R + 0_R)x = 0_R x + 0_R x \), thus \( 0_R x \) is an additive identity and \( 0_R x = 0_M \).

    \RItem{def:left_module_properties/module_zero_is_absorbing} For any \( t \in R \) we have that \( t 0_M = t (0_M + 0_M) = t 0_M + t 0_M \), thus \( t 0_M \) is an additive identity and \( t 0_M = 0_M \).
  \end{itemize}
\end{proof}

\begin{example}\label{ex:module/ideal_of_ring}
  Every unital ring \( R \) is a module over itself. Every ideal \( I \unlhd R \) is an \( R \)-module since it is closed under multiplication with \enquote{scalars} from \( R \).
\end{example}

\begin{definition}\label{def:left_module_kernel}
  Let \( X \) be an arbitrary set and let \( M \) be a left \( R \)-module\Tinyref{def:left_module}.

  The \Def{kernel} \( \ker(f) \) of a function \( f: X \to R \) is the preimage\Tinyref{def:function_preimage} \( f^{-1}(0_R) \).
\end{definition}

\begin{definition}\label{def:quotient_left_module}
  Let \( M \) be a left module and \( N \) be a submodule of \( M \). Define the \Def{quotient module}
  \begin{equation*}
    M / N \coloneqq \{ x + N \colon x \in M \}
  \end{equation*}
  with the operations
  \begin{align*}
    x + N \oplus y + N \coloneqq x + y + N.
    t \odot x + N \coloneqq tx + N.
  \end{align*}

  Define the canonical projection homomorphism
  \begin{align*}
    &\pi: G \to G / N \\
    &\pi(x) \coloneqq x + N.
  \end{align*}

  The kernel of \( \pi \) is precisely \( N \).
\end{definition}
\begin{proof}
  The proof of correctness is similar to \cref{def:quotient_group}.
\end{proof}

\begin{theorem}\label{thm:homomorphism_theorem_for_left_modules}
  Fix a ring \( R \). Let \( \varphi: M \to K \) be a homomorphism of left \( R \)-modules. We have the isomorphism
  \begin{equation*}
    M / \ker \varphi \cong \Img \varphi.
  \end{equation*}
\end{theorem}
\begin{proof}
  Analogous to \cref{thm:homomorphism_theorem_for_groups}.
\end{proof}

\begin{definition}\label{def:linear_operator}
  Let \( M \) and \( N \) be two left \( R \)-modules. We say that the function \( f: M \to N \) is \Def{linear} or a \Def{linear operator} if it satisfies the conditions
  \begin{description}
    \DItem{def:linear_operator/additivity}[additivity] \( f(x + y) = f(x) + f(y) \) for any \( x, y \in M \).
    \DItem{def:linear_operator/homogeneity}[homogeneity] \( f(tx) = t f(x) \) for any \( t \in R \) and \( x \in M \) (see \cref{def:homogenous_function}).
  \end{description}
\end{definition}

\begin{proposition}\label{thm:map_is_linear_iff_homomorphism}
  A function \( f: M \to N \) between left \( R \)-modules is linear\Tinyref{def:linear_operator} if and only if it is a module homomorphism in the sense of \cref{def:first_order_homomorphism}.
\end{proposition}
\begin{proof}
  Since \( (M, +) \) and \( (N, +) \) are groups, it follows from \cref{thm:group_homomorphism_single_condition} that \ref{def:linear_operator/additivity} is equivalent to the requirement that \( f \) is a homomorphism between \( (M, +) \) and \( (N, +) \).

  Now fix \( t \in R \). For \( f \) to be a homomorphism, it must satisfy
  \begin{equation*}
    f(\cdot_M^{(t)}(x)) = \cdot_t^{(N)}(f(x)),
  \end{equation*}
  which is just a more formal way to write \ref{def:linear_operator/homogeneity}.
\end{proof}

\begin{definition}\label{def:multilinear_function}
  Generalizing \cref{def:linear_operator}, if \( M_1, \ldots, M_k \) and \( N \) are \( R \)-modules, we say that the function
  \begin{equation*}
    f: M_1 \times \ldots \times M_k \to N
  \end{equation*}
  is \Def{multilinear} or \Def{\( k \)-linear} (\Def{bilinear} for \( k = 2 \), \Def{trilinear} for \( k = 3 \)) if it is linear in each component, that is, for each component \( i = 1, \ldots, k \), and for each tuple not containing elements from \( M_i \),
  \begin{equation*}
    (u_1, \ldots, u_{i-1}, u_{i+1}, \ldots, u_k) \in M_1 \times \ldots \times M_{i-1} \times M_{i+1} \times \ldots \times M_k \to N
  \end{equation*}
  the following function is linear:
  \begin{align*}
    &f_i: M_i \to N \\
    &f_i(u_i) \coloneqq f(u_1, \ldots, u_{i-1}, u_i, u_{i+1}, \ldots, u_k).
  \end{align*}
\end{definition}

\begin{definition}\label{def:abelian_group_z_module}\cite{Knapp2016BAlg}[375]
  Let \( G \) be an abelian group. Associate with \( G \) the \( \Z \)-module \( M \) with scalar multiplication
  \begin{align*}
    nu \coloneqq \begin{cases}
      0, &n = 0 \\
      u + \ldots + u, &n > 0 \\
      -((-n)u), &n < 0.
    \end{cases}
  \end{align*}
\end{definition}

\begin{proposition}\label{thm:abelian_group_iff_z_module}\cite{Knapp2016BAlg}[375]
  Every abelian group is isomorphic to exactly one \( \Z \)-module.
\end{proposition}
\begin{proof}
  We already saw in \cref{def:abelian_group_z_module} how every abelian group can be regarded as a \( \Z \)-module. Every \( \Z \)-module can then be identified with its additive group.

  Scalar multiplication ensures that there is exactly one way to define a \( \Z \)-module structure on an abelian group since \( na = (n-1)a + a \) and \( 0a = 0 \).
\end{proof}

\begin{definition}\label{def:left_module_direct_product}
  Let \( \{ X_i \}_{i \in I} \) be a nonempty family of left \( R \)-modules.

  Analogously to \cref{def:group_direct_product}, we define their \Def{direct product} as the module \( \prod_{i \in I} X_i \), the operations defined componentwise as
  \begin{align*}
    &\{ x_i \}_{i \in I} + \{ y_i \}_{i \in I}
    \coloneqq
    \{ x_i + y_i \}_{i \in I}, \\
    &t \{ x_i \}_{i \in I}
    \coloneqq
    t \{ t x_i \}_{i \in I}.
  \end{align*}

  We define their \Def{direct sum} as the submodule of \( \prod_{i \in I} X_i \)\Tinyref{def:left_module_direct_product} where only finitely many components of any module element are different from zero.
\end{definition}

\begin{proposition}\label{thm:mod_r_is_abelian}
  The category \( \Cat{Mod}_R \) of left \( R \)-modules is abelian.
\end{proposition}
\begin{proof}
  Similar to \cref{thm:ab_is_abelian}.
\end{proof}

\begin{proposition}\label{thm:module_categorical_limits}
  We are interested in categorical limits\Tinyref{def:categorical_limit} and colimits\Tinyref{def:categorical_colimit} in the category \( \Cat{Mod}_R \) of left-modules over \( R \). If \( \{ X_i \}_{i \in I} \) is an indexed family of \( R \)-modules, then
  \begin{defenum}
    \DItem{thm:module_categorical_limits/product} their categorical product\Tinyref{def:categorical_product} is their direct product\Tinyref{def:left_module_direct_product} \( \prod_{i \in I} X_i \), the projection morphisms being inherited from \cref{thm:set_categorical_limits/product}.

    \DItem{thm:module_categorical_limits/coproduct} their categorical coproduct\Tinyref{def:categorical_coproduct} is the direct sum\Tinyref{def:group_direct_product} \( \oplus_{i \in I} X_i \), the injection morphisms being inherited from \cref{thm:abelian_group_categorical_limits/coproduct}.
  \end{defenum}
\end{proposition}

\begin{definition}\label{def:linear_combination}
  Let \( M \) be a left \( R \)-module and let \( t_1, \ldots, t_n \in R \) and \( x_1, \ldots, x_n \in M \). We call
  \begin{equation*}
    x \coloneqq \sum_{k=1}^n t_k x_k
  \end{equation*}
  their \Def{linear combination} with \Def{coefficients} or \Def{scalars} \( t_1, \ldots, t_n \) and \Def{vectors} \( x_1, \ldots, x_n \).

  A linear combination is said to be \Def{trivial} if all coefficients are equal to \( 0_R \).
\end{definition}

\begin{definition}\label{def:left_module_linear_dependence}
  Let \( M \) be a left \( R \)-module and let \( A \subseteq M \). We say that the set \( A \) is \Def{linearly dependent} if there exist finitely many nonzero vectors \( x_1, \ldots, x_n \in A \) and scalars \( t_1, \ldots, t_n \in R \), where at least one scalar differs from zero, such that
  \begin{equation*}
    0_M = \sum_{i=1}^n t_i x_i.
  \end{equation*}

  If \( A \subseteq M \) is not linearly dependent, we say that it is \Def{linearly independent}.

  We say that the vectors \( x_1, \ldots, x_n \) are linearly dependent if the corresponding set \( \{ x_1, \ldots, x_n \} \) is linearly dependent.
\end{definition}

\begin{definition}\label{def:left_module_hamel_basis}
  A subset \( B \) of the left \( R \)-module \( M \) is called a \Def{Hamel basis} or simply \Def{basis} of \( M \) if \( B \) is a minimal\Tinyref{def:poset/maximal_minimal_element} (with respect to set inclusion) linearly independent subset of \( M \).
\end{definition}

\begin{definition}\label{def:free_left_module}[32]\cite[377]{Knapp2016BAlg}
  We say that the left \( R \)-module \( M \) is a \Def{free left module} if it has a basis\Tinyref{def:left_module_hamel_basis}.

  Let \( S \) be any set. If we regard \( R \) as a left module over itself, then the direct sum\Tinyref{thm:module_categorical_limits/coproduct}
  \begin{equation*}
    F(S) \coloneqq \oplus_{s \in S} R
  \end{equation*}
  with injections \( \{ \iota_s \}_{s \in S} \) is called the free left module \Def{generated by \( S \)}. Define the function
  \begin{align*}
    &\varphi: S \to F(S) \\
    &\varphi(s) \coloneqq \iota_s(1_R).
  \end{align*}

  The image \( \varphi(S) \) is then a basis of \( F(S) \).

  The cardinality of the basis of a free left module \( M \) is called the \Def{rank} \( \Rank M \) of \( M \). \Cref{thm:left_module_basis_cardinality} tells us that this rank is unique for commutative unital rings. If the rank of a module is finite, we say that the module is \Def{finitely generated}.

  We also denote \( F(S) = \Gen S \), especially in finitely generated modules.
\end{definition}

\begin{proposition}\label{thm:free_module_is_free_functor}
  The functor \( F: \Cat{Set} \to \Cat{Mod}_R \), defined pointwise in \cref{def:free_left_module}, is free\Tinyref{def:free_functor}.
\end{proposition}

\begin{proposition}\label{def:left_module_basis_decomposition}
  Let \( B \) be a basis of the free left \( R \)-module \( M \). Then each element \( u \) of \( M \) can be uniquely (up to a permutation) represented as a linear combination\Tinyref{def:linear_combination} of elements of \( B \).
\end{proposition}
\begin{proof}
  Let
  \begin{equation*}
    u = \sum_{i=1}^n t_i v_i
  \end{equation*}
  and
  \begin{equation*}
    u = \sum_{j=1}^m s_i w_i
  \end{equation*}
  be two representations of \( u \) as a linear combination over \( B \).

  Define the function
  \begin{align*}
    &t: M \to R \\
    &t(v) \coloneqq \begin{cases}
      t_i, &v = v_i, \\
      0, &v \not\in \{ v_1, \ldots, v_n \}.
    \end{cases}
  \end{align*}
  and analogously for \( s: M \to R \). Define the set
  \begin{equation*}
    B' \coloneqq \{ v_1, \ldots, v_n, w_1, \ldots, w_m \}.
  \end{equation*}

  Thus
  \begin{equation*}
    u = \sum_{b \in B'} t(b) b = \sum_{b \in B'} s(b) b
  \end{equation*}
  and
  \begin{equation*}
    0 = u - u = \sum_{b \in B'} (t(b) - s(b)) b.
  \end{equation*}

  The set \( B' \) is linearly independent as a subset of the basis \( B \), hence only a trivial linear combination can be the zero vector. This gives us
  \begin{equation*}
    t(b) = s(b), b \in B'.
  \end{equation*}

  In particular, the two decompositions of \( u \) along \( B \) are identical up to a permutation.
\end{proof}

\begin{definition}\label{def:left_module_basis_projection}
  Let \( M \) be a left \( R \)-module and let \( B \) be a basis of \( M \). For each \( b \in B \), we define the \text{coordinate projection functional} \( \pi_b: M \to R \) that gives us the unique coefficient in the basis decomposition. Thus, for every \( x \in M \) we have
  \begin{equation*}
    x = \sum_{b \in B} \pi_b(x) b.
  \end{equation*}

  The sum is well defined since only finitely many terms are nonzero.

  When the basis \( B \) is finite and ordered:
  \begin{equation*}
    B = \{ b_1, \ldots, b_n \},
  \end{equation*}
  we also write
  \begin{equation*}
    x = \sum_{i=1}^n x_i b_i.
  \end{equation*}
\end{definition}
\begin{proof}
  By \cref{def:left_module_basis_decomposition}, this decomposition is unique given a basis \( B \).
\end{proof}

\begin{proposition}\label{thm:left_module_basis_projections_are_linear}
  The basis projection maps\Tinyref{def:left_module_basis_projection} are linear.
\end{proposition}
\begin{proof}\mbox{}
  \begin{description}
    \RItem{def:linear_operator/homogeneity} Let \( t \in R \) and \( x \in M \). We have the unique decompositions
    \begin{align*}
      x &= \sum_{b \in B} \pi_b(x) b, \\
      tx &= \sum_{b \in B} \pi_b(tx) b.
    \end{align*}

    Since both decompositions have only finitely many terms, their difference also has only finitely many nonzero terms. Thus
    \begin{equation*}
      0
      =
      tx - tx
      =
      t \left( \sum_{b \in B} \pi_b(x) b \right) - \sum_{b \in B} \pi_b(tx) b
      =
      \sum_{b \in B} (t \pi_b(x) - \pi_b(tx)) b.
    \end{equation*}

    Since the vectors in \( B \) are linearly independent, no nontrivial linear combination can equal the zero vector. Thus, for all \( b \in B \),
    \begin{equation*}
      t \pi_b(x) = \pi_b(tx).
    \end{equation*}

    \RItem{def:linear_operator/additivity} Analogous.
  \end{description}
\end{proof}

\begin{theorem}\label{thm:linear_map_iff_function_on_basis}
  Let \( M \) and \( N \) be left \( R \)-modules and let \( B \) be a basis of \( M \). Then there exists a bijection between the functions\Tinyref{def:function} from \( B \) to \( N \) and the module homomorphisms\Tinyref{def:linear_operator} from \( M \) to \( N \), such that each linear map is an extension\Tinyref{def:function_extension} of the corresponding function.
\end{theorem}
\begin{proof}
  Let \( \varphi: M \to N \) be a homomorphism. Define the function
  \begin{align*}
    &f: B \to N \\
    &f(b) \coloneqq \varphi(b).
  \end{align*}

  Now define the linear map
  \begin{align*}
    &\hat \varphi: M \to N \\
    &\hat \varphi(x) \coloneqq \sum_{b \in B} \pi_b(x) f(b).
  \end{align*}

  Since the projections \( \pi_b(x) \) are linear functions by \cref{thm:left_module_basis_projections_are_linear} and since we only use the value of \( f \) on fixed vectors, it follows that \( \hat \varphi \) is also linear.

  It remains to show that \( \varphi = \hat \varphi \). For each \( x \in M \), by linearity of \( \varphi \) we have
  \begin{equation*}
    \hat \varphi(x)
    =
    \sum_{b \in B} \pi_b(x) f(b)
    =
    \sum_{b \in B} \pi_b(x) \varphi(b)
    =
    \varphi(x).
  \end{equation*}
\end{proof}

\begin{remark}\label{remark:linear_map_iff_function_on_basis}
  \Cref{thm:linear_map_iff_function_on_basis} is very powerful in that is allows to study linear maps given their value at only a small subset of vectors. The connection between multilinear maps\Tinyref{def:multilinear_function} and tensors\Tinyref{def:module_tensor_product} is based on this idea.
\end{remark}

\begin{corollary}\label{thm:linear_maps_agree_on_free_module_if_they_agree_on_basis}
  If two linear maps from the free left module \( M \) to \( N \) agree on a basis of \( M \), they agree on the whole module.
\end{corollary}

\begin{proposition}\label{thm:left_module_basis_cardinality}\cite{ProofWiki:bases_of_free_module_have_same_cardinality}
  All bases in a free left module over a commutative unital ring have the same cardinality.
\end{proposition}

\begin{definition}\label{def:module_tensor_product}\cite[574]{Knapp2016BAlg}
  Let \( R \) be a unital ring. Let \( M \) be a right \( R \)-module and \( N \) be a left \( R \)-module. Define the free abelian group\Tinyref{def:free_abelian_group} \( G \) generated by the basis \( M \times N \), that is,
  \begin{equation*}
    G \coloneqq \oplus_{(m,n) \in M \times N} \Z.
  \end{equation*}

  Denote by \( e_{m,n} \) the \( (m,n) \)-th basis vector and by \( t_{m,n} \) the \( (m,n) \)-th coordinate of \( t \in G \) (we can have only a finite amount of nonzero coordinates since \( G \) is a direct sum).

  We can regard \( G \) as a left \( R \)-module with scalar multiplication given by
  \begin{equation*}
    (r t)_{(m,n)} \coloneqq t_{(rm,n)}.
  \end{equation*}

  Let \( H \) be the submodule of \( G \) generated by
  \begin{itemize}
    \item \( e_{(m_1 - m_2, n)} - e_{(m_1,n)} - e_{(m_2,n)} \), \( m_1, m_2, n \in G \)
    \item \( e_{(m, n_1 - n_2)} - e_{(m,n_1)} - e_{(m,n_2)} \), \( m, n_1, n_2 \in G \)
    \item \( e_{(rm,n)} - e_{(m,rn)} \), \( m, n \in G \) and \( r \in R \)
  \end{itemize}

  Define the \Def{tensor product} of \( M \) and \( N \) to be the \( R \)-module 
  \begin{equation*}
    M \otimes N \coloneqq G / H.
  \end{equation*}
\end{definition}

\begin{theorem}\label{thm:tensor_product_universal_property}\cite[theorem 10.18]{Knapp2016BAlg}
  Let \( R \) be a unital ring. Let \( M \) be a right \( R \)-module and \( N \) be a left \( R \)-module and let \( M \otimes N \) be their tensor product\Tinyref{def:module_tensor_product} with \( q: M \times N \to M \otimes N \) being the corresponding quotient map.

  The tensor product \( M \otimes N \) satisfies the following universal property: for every \( R \)-module \( K \) and any bilinear map\Tinyref{def:multilinear_function} \( f: M \times N \to K \) there exists a unique map \( \hat f: M \otimes N \to K \) such that
  \begin{equation*}
    f = \hat f \circ q,
  \end{equation*}
  that is, the following diagram commutes:

  \begin{AlignedEquation}\label{thm:tensor_product_universal_property/diagram}
    \begin{mplibcode}
      beginfig(1);
        input metapost/graphs;

        v1 := thelabel("$M \times N$", origin);
        v2 := thelabel("$M \otimes N$", (2, 0) scaled u);
        v3 := thelabel("$K$", (1, -1) scaled u);

        a1 := straight_arc(v1, v2);
        a2 := straight_arc(v2, v3);
        a3 := straight_arc(v1, v3);

        draw_vertices(v);
        draw_arcs(a);

        label.top("$q$", straight_arc_midpoint of a1);
        label.lrt("$\hat f$", straight_arc_midpoint of a2);
        label.llft("$f$", straight_arc_midpoint of a3);
      endfig;
    \end{mplibcode}
  \end{AlignedEquation}
\end{theorem}

\begin{proposition}\label{thm:tensor_product_with_underlying_ring}\cite[677]{Knapp2016BAlg}
  Let \( R \) be a unital ring (regarded as a right module) and \( B \) be a left \( R \)-module. Their tensor product\Tinyref{def:module_tensor_product} satisfies
  \begin{equation*}
    R \otimes M \cong M.
  \end{equation*}
\end{proposition}

\begin{definition}\label{def:algebra_over_ring}\cite[408]{Knapp2016BAlg}
  Let \( R \) be a commutative unital ring. We say that the left \( R \)-module \( A \) is an \( R \)-\Def{algebra} if we define an additional bilinear \Def{vector multiplication} operation
  \begin{equation*}
    \odot: A \times A \to A
  \end{equation*}
  such that for \( x, y \in M \) and \( t \in R \)
  \begin{equation*}
    t \cdot (x \odot y) = (t \cdot x) \odot y = x \odot (t \cdot y).
  \end{equation*}

  Both vector and scalar multiplication are usually denoted by juxtaposition.

  If \( \odot \) is associative, commutative, unital or invertible, we add this prefix to \( A \), e.g. A is a commutative algebra if \( \odot \) is commutative.
\end{definition}

\begin{proposition}\label{thm:functions_over_ring_form_algebra}
  Let \( X \) be an arbitrary nonempty set and \( R \) be a commutative unital ring. Define
  \begin{equation*}
    A \coloneqq \Cat{Set}(X, R)
  \end{equation*}
  to be the set of all functions from \( X \) to \( R \)\Tinyref{def:category_of_sets}. Then \( A \) is an \( R \)-algebra with the operations being defined pointwise, that is,
  \begin{align*}
    [f + g](x) &\coloneqq f(x) + g(x) \\
    [f \odot g](x) &\coloneqq f(x) \circ g(x) \\
    [rf](x) &\coloneqq r f(x) 
  \end{align*}

  We call the algebra \( A \) the \Def{algebra of functions} from \( X \) to \( R \).

  If \( X \) itself has a ring structure, we consider the set of ring homomorphisms\Tinyref{thm:ring_homomorphism_simpler_conditions}
  \begin{equation*}
    \Cat{Ring}(X, R),
  \end{equation*}
  which is usually a strict subset of \( \Cat{Set}(X, R) \). This set is usually denoted by \( \hom(X, R) \).

  If \( R \) is a module but not necessarily a ring, then \( \Cat{Set}(X, R) \) is a only module since we do not necessarily have multiplication. See \cref{def:linear_operator}.
\end{proposition}

\begin{definition}\label{def:homogenous_function}
  Let \( M \) and \( N \) be left \( R \)-modules. We say that the function \( f: M \to N \) is homogeneous with degree \( n \) if for all \( t \in R \) and \( x \in M \) we have
  \begin{equation*}
    f(t x) = t^n f(x).
  \end{equation*}
\end{definition}
