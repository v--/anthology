\subsection{Modules}\label{subsec:modules}

\begin{definition}\label{def:module_over_ring}\cite[374]{Knapp2016BAlg}
  Let \( R \) be a unital ring\Tinyref{def:semiring/unital_ring}. Unlike the definition for groups\Tinyref{def:magma/group} and rings\Tinyref{def:semiring/ring}, a (left) \Def{\( R \)-module} \( M \) over \( R \) has binary operations of different types:
  \begin{description}
    \item[addition] \( + \) forms a group\Tinyref{def:magma/group}. The additive identity is usually denoted by \( 0_M \).

    \item[scalar multiplication] \( \cdot: R \times M \to M \) (usually written using juxtaposition) is associative \Tinyref{def:algebraic_theory/associativity} and unital\Tinyref{def:algebraic_theory/identity}. In order for \cref{def:algebraic_theory} to make sense here, we define operations
    \begin{equation*}
      \cdot^{(t)}(x): M \to M
    \end{equation*}
    for each \( t \in R \).
  \end{description}

  We require that \( \cdot \) is distributive over \( + \) \cref{def:algebraic_theory/distributivity}, that is, the following are satisfied for \( x, y \in M \) and \( s, t \in R \):
  \begin{description}
    \DItem{def:left_module/associativity} \( s (t x) = (s t) x \).
    \DItem{def:left_module/scalar_distributivity}[scalar distributivity] \( (s + t) x = s x + t x \).
    \DItem{def:left_module/vector_distributivity}[vector distributivity] \( t (x + t) = t x + t y \).
    \DItem{def:left_module/identity} \( 1_R x = x \).
  \end{description}

  Related notions are
  \begin{defenum}
    \DItem{def:module_over_ring/right_module} \Def{Right modules} are defined analogously but with the scalar on the right side. In fact, every left \( R \)-module is isomorphic to exactly one right \( R^{-1} \)-module, where \( R^{-1} \) is the opposite ring\Tinyref{def:opposite_ring}.

    \DItem{def:module_over_ring/bimodule} An \Def{\( (R, S) \)-bimodule} \( M \) is a left \( R \)-module and a right \( S \)-module such that for \( r \in R \), \( s \in S \) and \( x \in M \) we have
    \begin{equation*}
      (rx)s = r(xs).
    \end{equation*}
  \end{defenum}

  In analogy with vector spaces\Tinyref{def:vector_space}, we call elements of \( R \) scalars and elements of \( M \) vectors. See \cref{def:vector_space}.

  We denote the category of left-modules over \( R \) by \( \Cat{Mod}_R \).
\end{definition}

\begin{remark}\label{remark:commutative_modules}
  We are mostly interested in modules over commutative unital rings, where \( R = R^{-1} \) and thus left and right modules coincide. Hence we only refer to \( R \)-modules.

  Despite this, where possible, we give definitions and theorems about left modules.
\end{remark}

\begin{proposition}\label{def:left_module_properties}
  Any left \( R \)-module \( M \) has the following basic properties:
  \begin{defenum}
    \DItem{def:left_module_properties/ring_zero_is_absorbing} Multiplication by \( 0_R \) is absorbing\Tinyref{def:algebraic_theory/absorbing_element}, that is, \( 0_R x = 0_M \) for any \( x \in M \).

    \DItem{def:left_module_properties/module_zero_is_absorbing} Multiplication by \( 0_M \) is absorbing, that is, \( t 0_M = 0_M \) for any \( t \in R \).
  \end{defenum}
\end{proposition}
\begin{proof}\mbox{}
  \begin{itemize}
    \RItem{def:left_module_properties/ring_zero_is_absorbing} For any \( x \in M \) we have that \( 0_R x = (0_R + 0_R)x = 0_R x + 0_R x \), thus \( 0_R x \) is an additive identity and \( 0_R x = 0_M \).

    \RItem{def:left_module_properties/module_zero_is_absorbing} For any \( t \in R \) we have that \( t 0_M = t (0_M + 0_M) = t 0_M + t 0_M \), thus \( t 0_M \) is an additive identity and \( t 0_M = 0_M \).
  \end{itemize}
\end{proof}

\begin{example}\label{ex:left_module/ideal_of_ring}
  Every unital ring \( R \) is a left module over itself. Every ideal \( I \unlhd R \) is an \( R \)-module since it is closed under multiplication with \enquote{scalars} from \( R \).
\end{example}

\begin{definition}\label{def:left_module_kernel}
  Let \( X \) be an arbitrary set and let \( M \) be a left \( R \)-module\Tinyref{def:module_over_ring}.

  The \Def{kernel} \( \ker(f) \) of a function \( f: X \to R \) is the preimage\Tinyref{def:function_preimage} \( f^{-1}(0_R) \).
\end{definition}

\begin{definition}\label{def:linear_operator}
  Let \( M \) and \( N \) be two left \( R \)-modules. We say that the function \( f: M \to N \) is \Def{linear} or a \Def{linear operator} if it satisfies the conditions
  \begin{description}
    \DItem{def:linear_operator/additivity}[additivity] \( f(x + y) = f(x) + f(y) \) for any \( x, y \in M \).
    \DItem{def:linear_operator/homogeneity}[homogeneity] \( t f(x) = f(tx) \) for any \( t \in R \) and \( x \in M \).
  \end{description}
\end{definition}

\begin{proposition}\label{thm:map_is_linear_iff_homomorphism}
  A function \( f: M \to N \) between left \( R \)-modules is linear\Tinyref{def:linear_operator} if and only if it is a module homomorphism in the sense of \cref{def:first_order_homomorphism}.
\end{proposition}
\begin{proof}
  Since \( (M, +) \) and \( (N, +) \) are groups, it follows from \cref{thm:group_homomorphism_single_condition} that \ref{def:linear_operator/additivity} is equivalent to the requirement that \( f \) is a homomorphism between \( (M, +) \) and \( (N, +) \).

  Now fix \( t \in R \). For \( f \) to be a homomorphism, it must satisfy
  \begin{equation*}
    f(\cdot_M^{(t)}(x)) = \cdot_t^{(N)}(f(x)),
  \end{equation*}
  which is just a more formal way to write \ref{def:linear_operator/homogeneity}.
\end{proof}

\begin{definition}\label{def:multilinear_function}
  Generalizing \cref{def:linear_operator}, if \( M_1, \ldots, M_k \) and \( N \) are \( R \)-modules, we say that the function
  \begin{equation*}
    f: M_1 \times \ldots \times M_k \to N
  \end{equation*}
  is \Def{multilinear} or \Def{\( k \)-linear} (\Def{bilinear} for \( k = 2 \), \Def{trilinear} for \( k = 3 \)) if it is linear in each component, that is, for each component \( i = 1, \ldots, k \), and for each tuple not containing elements from \( M_i \),
  \begin{equation*}
    (u_1, \ldots, u_{i-1}, u_{i+1}, \ldots, u_k) \in M_1 \times \ldots \times M_{i-1} \times M_{i+1} \times \ldots \times M_k \to N
  \end{equation*}
  the following function is linear:
  \begin{align*}
    &f_i: M_i \to N \\
    &f_i(u_i) \coloneqq f(u_1, \ldots, u_{i-1}, u_i, u_{i+1}, \ldots, u_k).
  \end{align*}
\end{definition}

\begin{definition}\label{def:abelian_group_z_module}\cite{Knapp2016BAlg}[375]
  Let \( G \) be an abelian group. Associate with \( G \) the \( \Z \)-module \( M \) with scalar multiplication
  \begin{align*}
    nu \coloneqq \begin{cases}
      0, &n = 0 \\
      u + \ldots + u, &n > 0 \\
      -((-n)u), &n < 0.
    \end{cases}
  \end{align*}
\end{definition}

\begin{proposition}\label{thm:abelian_group_iff_z_module}\cite{Knapp2016BAlg}[375]
  Every abelian group is isomorphic to exactly one \( \Z \)-module.
\end{proposition}
\begin{proof}
  We already saw in~\cref{def:abelian_group_z_module} how every abelian group can be regarded as a \( \Z \)-module. Every \( \Z \)-module can then be identified with its additive group.

  Scalar multiplication ensures that there is exactly one way to define a \( \Z \)-module structure on an abelian group since \( na = (n-1)a + a \) and \( 0a = 0 \).
\end{proof}

\begin{definition}\label{def:left_module_direct_product}
  Let \( \{ X_i \}_{i \in I} \) be a nonempty family of left \( R \)-modules.

  Analogously to \cref{def:group_direct_product}, we define their \Def{direct product} as the module \( \prod_{i \in I} X_i \), the operations defined componentwise as
  \begin{align*}
    &\{ x_i \}_{i \in I} + \{ y_i \}_{i \in I}
    \coloneqq
    \{ x_i + y_i \}_{i \in I}, \\
    &t \{ x_i \}_{i \in I}
    \coloneqq
    t \{ t x_i \}_{i \in I}.
  \end{align*}

  We define their \Def{direct sum} as the submodule of \( \prod_{i \in I} X_i \)\Tinyref{def:left_module_direct_product} where only finitely many components of any module element are different from zero.
\end{definition}

\begin{proposition}\label{thm:mod_r_is_abelian}
  The category \( \Cat{Mod}_R \) of left \( R \)-modules is abelian.
\end{proposition}
\begin{proof}
  Similar to \cref{thm:ab_is_abelian}.
\end{proof}

\begin{proposition}\label{thm:left_module_categorical_limits}
  We are interested in categorical limits\Tinyref{def:categorical_limit} and colimits\Tinyref{def:categorical_colimit} in the category \( \Cat{Mod}_R \) of left-modules over \( R \). If \( \{ X_i \}_{i \in I} \) is an indexed family of \( R \)-modules, then
  \begin{defenum}
    \DItem{thm:left_module_categorical_limits/product} their categorical product\Tinyref{def:categorical_product} is their direct product\Tinyref{def:left_module_direct_product} \( \prod_{i \in I} X_i \), the projection morphisms being inherited from \cref{thm:set_categorical_limits/product}.

    \DItem{thm:left_module_categorical_limits/coproduct} their categorical coproduct\Tinyref{def:categorical_coproduct} is the direct sum\Tinyref{def:group_direct_product} \( \oplus_{i \in I} X_i \), the injection morphisms being inherited from \cref{thm:abelian_group_categorical_limits/coproduct}.
  \end{defenum}
\end{proposition}

\begin{definition}\label{def:linear_combination}
  Let \( M \) be a left \( R \)-module and let \( t_1, \ldots, t_n \in R \) and \( x_1, \ldots, x_n \in M \). We call
  \begin{equation*}
    x \coloneqq \sum_{k=1}^n t_k x_k
  \end{equation*}
  their \Def{linear combination} with \Def{coefficients} or \Def{scalars} \( t_1, \ldots, t_n \) and \Def{vectors} \( x_1, \ldots, x_n \).

  A linear combination is said to be \Def{trivial} if all coefficients are equal to \( 0_R \).
\end{definition}

\begin{definition}\label{def:left_module_linear_dependence}
  Let \( M \) be a left \( R \)-module and let \( A \subseteq M \). We say that the set \( A \) is \Def{linearly dependent} if there exist nonzero vectors \( x_1, \ldots, x_n \in A \) and scalars \( t_1, \ldots, t_n \in R \), where at least one scalar differs from zero, such that
  \begin{equation*}
    0_M = \sum_{i=1}^n t_i x_i.
  \end{equation*}

  We say that the vectors \( x_1, \ldots, x_n \) are linearly dependent if the corresponding set \( \{ x_1, \ldots, x_n \} \) is linearly dependent.
\end{definition}

\begin{definition}\label{def:left_module_basis}
  The subset \( B \) of the left \( R \)-module \( M \) is called a \Def{basis of \( M \)} if \( B \) is linearly independent and no proper superset of \( B \) is linearly independent.
\end{definition}

\begin{definition}\label{def:free_left_module}[32]\cite{Kocev2016}
  We say that the left \( R \)-module \( M \) is a \Def{free left module} if it has a basis\Tinyref{def:left_module_basis}.

  Let \( S \) be any set. If we regard \( R \) as a left module over itself, then the direct sum\Tinyref{thm:left_module_categorical_limits/coproduct}
  \begin{equation*}
    M \coloneqq \oplus_{s \in S} R
  \end{equation*}
  with injections \( \{ \iota_s \}_{s \in S} \) is called the free left module \Def{generated by \( S \)}. Define the function
  \begin{align*}
    &\varphi: S \to M \\
    &\varphi(s) \coloneqq \iota_s(1_R).
  \end{align*}

  The image \( \varphi(S) \) is then a basis of \( M \).

  If a free left module has a finite basis, we say that it is \Def{finitely generated}.

  The cardinality of the basis of a free left module \( M \) is called the \Def{rank} \( \Rank M \) of \( M \). \Cref{thm:free_left_module_basis_cardinality} tells us that this rank is unique for commutative unital rings.
\end{definition}

\begin{proposition}\label{def:left_module_basis_decomposition}
  Let \( B \) be a basis of the free left \( R \)-module \( M \). Then each element \( u \) of \( M \) can be uniquely (up to a rearrangement) represented as a linear combination\Tinyref{def:linear_combination} of elements of \( B \).
\end{proposition}
\begin{proof}
  Assume\LEM that
  \begin{equation*}
    u = t_1 a_1 + \ldots + t_n a_n = \beta_1 b_1 + \ldots + \beta_n b_m,
  \end{equation*}
  where \( t_1, \ldots, t_n, \beta_1, \ldots, \beta_n \in R \) and \( a_1, \ldots, a_n, b_1, \ldots, b_m \in B \). With no loss of generality, assume that all scalars \( t_1, \ldots, t_n, \beta_1, \ldots, \beta_n \) are nonzero.

  Thus
  \begin{equation*}
    0 = u - u = (t_1 - 0) a_1 + \ldots + (t_n - 0) a_n + (0 - \beta_1) b_1 + \ldots + (0 - \beta_m) b_m
  \end{equation*}

  For every \( i = 1, \ldots, n \) we have two possibilities:
  \begin{itemize}
    \item If \( a_i \not\in \{ b_1, \ldots, b_n \} \), we necessarily have \( t_i = 0 \), which contradicts our assumption.
    \item If \( a_i = b_j \) for some \( j = 1, \ldots, m \), it follows that \( t_i = \beta_j \).
  \end{itemize}

  Analogously, for \( j = 1, \ldots, m \), \( \beta_j \) equals \( t_i \) for some \( i = 1, \ldots, n \). Hence \( n = m \) and \( b_1, \ldots, b_m \) is simply a permutation\Tinyref{def:symmetric_group} of \( a_1, \ldots, a_n \).
\end{proof}

\begin{definition}\label{def:free_left_module_basis_projection}
  Let \( M \) be a left \( R \)-module and let \( B \) be a basis of \( M \). For each \( b \in B \), we define the \text{projection function} \( \pi_b: M \to R \) that gives us the unique coefficient in the basis decomposition. Thus, for every \( x \in M \) we have
  \begin{equation*}
    x = \sum_{b \in B} \pi_b(x) b.
  \end{equation*}
\end{definition}
\begin{proof}
  By \cref{def:left_module_basis_decomposition}, this decomposition is unique given a basis \( B \).
\end{proof}

\begin{proposition}\label{thm:free_left_module_basis_projections_are_linear}
  The basis projection maps\Tinyref{def:free_left_module_basis_projection} are linear.
\end{proposition}
\begin{proof}\mbox{}
  \begin{description}
    \RItem{def:linear_operator/homogeneity} Let \( t \in R \) and \( x \in M \). We have the unique decompositions
    \begin{align*}
      x &= \sum_{b \in B} \pi_b(x) b, \\
      tx &= \sum_{b \in B} \pi_b(tx) b.
    \end{align*}

    Thus
    \begin{equation*}
      0
      =
      tx - tx
      =
      t \left( \sum_{b \in B} \pi_b(x) b \right) - \sum_{b \in B} \pi_b(tx) b
      =
      \sum_{b \in B} (t \pi_b(x) - \pi_b(tx)) b.
    \end{equation*}

    Since the vectors in \( B \) are linearly independent, no nontrivial linear combination can equal the zero vector. Thus, for all \( b \in B \),
    \begin{equation*}
      t \pi_b(x) = \pi_b(tx).
    \end{equation*}

    \RItem{def:linear_operator/additivity} Analogous.
  \end{description}
\end{proof}

\begin{theorem}\label{thm:linear_map_iff_function_on_basis}
  Let \( M \) and \( N \) be left \( R \)-modules and let \( B \) be a basis of \( M \). Then there exists a bijection between the functions\Tinyref{def:function} from \( B \) to \( N \) and the module homomorphisms\Tinyref{def:linear_operator} from \( M \) to \( N \), such that each linear map is an extension\Tinyref{def:function_extension} of the corresponding function.
\end{theorem}
\begin{proof}
  Let \( \varphi: M \to N \) be a homomorphism. Define the function
  \begin{align*}
    &f: B \to N \\
    &f(b) \coloneqq \varphi(b).
  \end{align*}

  Now define the linear map
  \begin{align*}
    &\hat \varphi: M \to N \\
    &\hat \varphi(x) \coloneqq \sum_{b \in B} \pi_b(x) f(b).
  \end{align*}

  Since the projections \( \pi_b(x) \) are linear functions by \cref{thm:free_left_module_basis_projections_are_linear} and since we only use the value of \( f \) on fixed vectors, it follows that \( \hat \varphi \) is also linear.

  It remains to show that \( \varphi = \hat \varphi \). For each \( x \in M \), by linearity of \( \varphi \) we have
  \begin{equation*}
    \hat \varphi(x)
    =
    \sum_{b \in B} \pi_b(x) f(b)
    =
    \sum_{b \in B} \pi_b(x) \varphi(b)
    =
    \varphi(x).
  \end{equation*}
\end{proof}

\begin{remark}\label{remark:linear_map_iff_function_on_basis}
  \Cref{thm:linear_map_iff_function_on_basis} is very powerful in that is allows to study linear maps given their value at only a small subset of vectors. The connection between multilinear maps\Tinyref{def:multilinear_function} and tensors\Tinyref{def:module_tensor_product} is based on this idea.
\end{remark}

\begin{proposition}\label{thm:free_left_module_basis_cardinality}\cite{ProofWiki:bases_of_free_module_have_same_cardinality}
  All bases in a free module over a commutative unital ring have the same cardinality.
\end{proposition}

\begin{definition}\label{def:module_tensor_product}\cite[574]{Knapp2016BAlg}
  Let \( R \) be a unital ring. Let \( M \) be a right \( R \)-module and \( N \) be a left \( R \)-module. Define the free abelian group\Tinyref{def:free_abelian_group} \( G \) generated by the basis \( M \times N \), that is,
  \begin{equation*}
    G \coloneqq \oplus_{(m,n) \in M \times N} \Z.
  \end{equation*}

  Denote by \( e_{m,n} \) the \( (m,n) \)-th basis vector and by \( t_{m,n} \) the \( (m,n) \)-th coordinate of \( t \in G \) (we can have only a finite amount of nonzero coordinates since \( G \) is a direct sum).

  We can regard \( G \) as a left \( R \)-module with scalar multiplication given by
  \begin{equation*}
    (r t)_{(m,n)} \coloneqq t_{(rm,n)}.
  \end{equation*}

  Let \( H \) be the submodule of \( G \) generated by
  \begin{itemize}
    \item \( e_{(m_1 - m_2, n)} - e_{(m_1,n)} - e_{(m_2,n)} \), \( m_1, m_2, n \in G \)
    \item \( e_{(m, n_1 - n_2)} - e_{(m,n_1)} - e_{(m,n_2)} \), \( m, n_1, n_2 \in G \)
    \item \( e_{(rm,n)} - e_{(m,rn)} \), \( m, n \in G \) and \( r \in R \)
  \end{itemize}

  Define the \Def{tensor product} of \( M \) and \( N \) to be the \( R \)-module 
  \begin{equation*}
    M \otimes N \coloneqq G / H.
  \end{equation*}
\end{definition}

\begin{theorem}\label{thm:tensor_product_universal_property}\cite[theorem 10.18]{Knapp2016BAlg}
  Let \( R \) be a unital ring. Let \( M \) be a right \( R \)-module and \( N \) be a left \( R \)-module and let \( M \otimes N \) be their tensor product\Tinyref{def:module_tensor_product} with \( q: M \times N \to M \otimes N \) being the corresponding quotient map.

  The tensor product \( M \otimes N \) satisfies the following universal property: for every \( R \)-module \( K \) and any bilinear map\Tinyref{def:multilinear_function} \( f: M \times N \to K \) there exists a unique map \( \hat f: M \otimes N \to K \) such that
  \begin{equation*}
    f = \hat f \circ q,
  \end{equation*}
  that is, the following diagram commutes:

  \begin{AlignedEquation}\label{thm:tensor_product_universal_property/diagram}
    \begin{mplibcode}
      beginfig(1);
        input metapost/graphs;

        v1 := thelabel("$M \times N$", origin);
        v2 := thelabel("$M \otimes N$", (2, 0) scaled u);
        v3 := thelabel("$K$", (1, -1) scaled u);

        a1 := straight_arc(v1, v2);
        a2 := straight_arc(v2, v3);
        a3 := straight_arc(v1, v3);

        draw_vertices(v);
        draw_arcs(a);

        label.top("$q$", straight_arc_midpoint of a1);
        label.lrt("$\hat f$", straight_arc_midpoint of a2);
        label.llft("$f$", straight_arc_midpoint of a3);
      endfig;
    \end{mplibcode}
  \end{AlignedEquation}
\end{theorem}

\begin{proposition}\label{thm:tensor_product_with_underlying_ring}\cite[677]{Knapp2016BAlg}
  Let \( R \) be a unital ring (regarded as a right module) and \( B \) be a left \( R \)-module. Their tensor product\Tinyref{def:module_tensor_product} satisfies
  \begin{equation*}
    R \otimes M \cong M.
  \end{equation*}
\end{proposition}

\begin{definition}\label{def:algebra_over_a_ring}\cite[4]{Kocev2016}
  Let \( R \) be a commutative unital ring. We say that the \( R \)-module \( A \) is an \Def{\( R \)-algebra} if we define an additional \Def{vector multiplication} operation
  \begin{equation*}
    \odot: A \times A \to A
  \end{equation*}
  such that for \( x, y \in M \) and \( t \in R \)
  \begin{equation*}
    t \cdot (x \odot y) = (t \cdot x) \odot y = x \odot (t \cdot y).
  \end{equation*}

   Both vector and scalar multiplication are usually denoted by juxtaposition.
\end{definition}

\begin{proposition}\label{thm:functions_over_ring_form_algebra}
  Let \( X \) be an arbitrary nonempty set and \( R \) be a commutative unital ring. Define
  \begin{equation*}
    A \coloneqq \Cat{Set}(X, R)
  \end{equation*}
  to be the set of all functions from \( X \) to \( R \)\Tinyref{def:category_of_sets}. Then \( A \) is an \( R \)-algebra with the operations being defined pointwise, that is,
  \begin{align*}
    [f + g](x) &\coloneqq f(x) + g(x) \\
    [f \circ g](x) &\coloneqq f(x) \circ g(x) \\
    [rf](x) &\coloneqq r f(x) 
  \end{align*}

  We call the algebra \( A \) the \Def{algebra of functions} from \( X \) to \( R \).

  If \( X \) itself has a ring structure, we consider the set of ring homomorphisms\Tinyref{thm:ring_homomorphism_simpler_conditions}
  \begin{equation*}
    \Cat{Ring}(X, R),
  \end{equation*}
  which is usually a strict subset of \( \Cat{Set}(X, R) \). This set is usually denoted by \( \hom(X, R) \).

  If \( R \) is a module but not necessarily a ring, then \( \Cat{Set}(X, R) \) is a only module since we do not necessarily have multiplication. See \cref{def:linear_operator}.
\end{proposition}
