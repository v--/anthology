\section{Commutative algebra}\label{sec:commutative_algebra}

\begin{remark}\label{remark:polynomial_commutative_ring}
  In this whole section, \( R \) will refer to a nontrivial commutative unital ring\Tinyref{def:semiring/commutative_unital_ring}.

  Since \( R \) is commutative, left and right modules over \( R \) are equivalent. We will only refer to either of them as simply \enquote{modules}.
\end{remark}

\subsection{Polynomials}\label{subsec:polynomials}

\begin{definition}\label{def:polynomial}\cite[149]{Knapp2016BAlg}
  A \Def{polynomial} \( p \) over \( R \) is a sequence of members of \( R \) called \Def{coefficients},
  \begin{equation*}
    p \coloneqq ( a_0, a_1, a_2, \ldots ) \subseteq R,
  \end{equation*}
  such that only finitely many coefficients are nonzero.

  \begin{defenum}
    \DItem{def:polynomial/zero_polynomial} An exception to most rules is the \Def{zero polynomial}, all of whose coefficients are zeroes.

    \DItem{def:polynomial/leading_coefficient} The last nonzero coefficient of a nonzero polynomial is called the \Def{leading coefficient} and is denoted by \( \LC(p) \). If \( \LC(p) = 1 \), we call the polynomial \Def{2}.

    \DItem{def:polynomial/degree} The zero-based index of the leading coefficient is called the \Def{degree} of the polynomial as is denoted by \( \deg(p) \). That is, if only \( a_0 \) is nonzero, then \( \deg(p) = a_0 \). The degree of the zero polynomial is left undefined.

    \DItem{def:polynomial/expression} It is conventional to write a polynomial of degree \( n \) as the expression\Tinyref{def:language}
    \begin{equation*}
      p(X) = a_n X^n + a_{n-1} X^{n-1} + \ldots + a_2 X^2 + a_1 X + a_0 = \sum_{i=0}^n a_i X^i
    \end{equation*}
    and the zero polynomial as
    \begin{equation*}
      p(X) \coloneqq 0.
    \end{equation*}

    This is consistent with addition as defined in \cref{def:algebra_of_polynomials/addition}.

    We use capital letters to highlight that this is not a function - see \Tinyref{def:polynomial_function}. It is customary to call \( X \) the \Def{indeterminate} of \( p(X) \) and to say that \( p(X) \) is a polynomial in one indeterminate (compare to \cref{def:multivariate_polynomial}).

    \DItem{def:polynomial/monomial} A \Def{monomial} is a polynomial with only one nonzero element. Symbolically, monomials can be represented as
    \begin{equation*}
      a_i X^i.
    \end{equation*}

    By \cref{def:algebra_of_polynomials/addition}, this is consistent with the representation defined in \cref{def:polynomial/expression}:
    \begin{equation*}
      p(X) = \sum_{i=0}^n a_i X^i.
    \end{equation*}

    \DItem{def:polynomial/degree_names} Polynomials of degree \( n \) with special names include
    \begin{itemize}
      \item \Def{constant} for the zero polynomial or if \( n = 0 \).
      \item \Def{linear} if \( n = 1 \).
      \item \Def{quadratic} if \( n = 2 \).
      \item \Def{cubic} if \( n = 3 \).
      \item \Def{quartic} if \( n = 4 \).
      \item \Def{quintic} if \( n = 5 \).
    \end{itemize}
  \end{defenum}
\end{definition}

\begin{definition}\label{def:algebra_of_polynomials}
  Denote by \( R[X] \) the set of polynomials over \( R \). Note that it is bijective with \( c_{00} \) and we can inherit pointwise addition and scalar multiplication from there. That is,

  \begin{defenum}
    \DItem{def:algebra_of_polynomials/addition} We define \Def{polynomial addition} point as
    \begin{align*}
      &+: R[X] \times R[X] \to R[X] \\
      &(a_0, a_1, \ldots) + (b_0, b_1, \ldots) \coloneqq (a_0 + b_0, b_0 + b_1, \ldots)
    \end{align*}

    This operation is consistent with the symbolic representations of polynomials\Tinyref{def:polynomial/expression}. Indeed, if \( p(X) \) has degree \( n \), then only the first \( n + 1 \) elements may be nonzero and
    \begin{equation*}
      (a_0, a_1, \ldots, a_n, 0, 0, \ldots) = \sum_{i=0}^n (0, \ldots, 0, a_i, 0, \ldots).
    \end{equation*}

    \DItem{def:algebra_of_polynomials/scalar_multiplication} We define \Def{scalar multiplication} as
    \begin{align*}
      &\cdot: R[X] \times R[X] \to R[X] \\
      &t \cdot (a_0, a_1, \ldots) \coloneqq (t a_0, t b_1, \ldots)
    \end{align*}

    \DItem{def:algebra_of_polynomials/matrix_multiplication} In order to make \( R[X] \) into an algebra\Tinyref{def:algebra_over_ring}, we define \Def{polynomial multiplication} \( \odot: R[X] \times R[X] \to R[X] \) as follows: if \( (a_0, a_1, \ldots) \) and \( (b_0, b_1, \ldots) \) are polynomials, their product is defined to be the polynomial with coefficients
    \begin{equation}
      c_l \coloneqq \sum_{i+j=l} a_i b_j, l = 0, 1, \ldots.
    \end{equation}

    Polynomial multiplication is bilinear, associative and commutative.
  \end{defenum}

  We will implicitly use the canonical embedding \( \iota: R \to R[X] \), which sends an element \( r \) of \( R \) into the constant polynomial \( p(X) \coloneqq r \).

  We usually refer to \( R[X] \) as the \Def{polynomial ring}, especially since scalar multiplication is the same multiplication by constants.
\end{definition}

\begin{proposition}\label{thm:polynomial_degree_properties}
  The polynomial degree has the following basic properties:
  \begin{thmenum}
    \DItem{thm:polynomial_degree_properties/sum} For nonzero polynomials \( p, q \in R[X] \) with \( p \neq -q \), we have
    \begin{equation*}
      \deg (p + q) \leq \max \{ \deg p, \deg q \}.
    \end{equation*}

    \DItem{thm:polynomial_degree_properties/product} For nonzero polynomials \( p, q \in R[X] \) with \( pq \neq 0 \), we have
    \begin{equation*}
      \deg (pq) \leq \deg p + \deg q,
    \end{equation*}
    with equality holding if \( R \) is an integral domain.

    The requirement that \( pq \neq 0 \) may also be dropped if \( R \) is an integral domain as per \cref{thm:polynomials_over_integral_domain_are_integral_domain}.
  \end{thmenum}
\end{proposition}
\begin{proof}
  Fix nonzero polynomials
  \begin{align*}
    p(X) &\coloneqq \sum_{i=0}^n a_i X^i, \\
    q(X) &\coloneqq \sum_{j=0}^m b_j X^j.
  \end{align*}

  \begin{description}
    \RItem{thm:polynomial_degree_properties/sum} Additionally assume that \( p \neq -q \) since otherwise \( p + q = 0 \) and \( \deg(p + q) \) is undefined. Thus there exists at least one index \( i = 1, 2, \ldots \) so that \( a_i \neq b_i \). Denote by \( k \) the largest such index (only finitely many are nonzero). Then
    \begin{equation*}
      a_i = b_i = 0 \text{ for } i > k.
    \end{equation*}

    Therefore \( \deg(p + q) = k \). Note that \( k \) cannot exceed both \( \deg p \) and \( \deg q \) because it corresponds to a nonzero coefficient. Thus \( k \leq \max\{ \deg p, \deg q \} \).

    \RItem{thm:polynomial_degree_properties/product} By assumption \( pq \neq 0 \) so there exists at least one nonzero coefficient, say \( c_k \). Obviously \( k \leq \deg p + \deg q \) since the highest possible degree of \( pq \) is \( \deg p + \deg q \). Thus
    \begin{equation*}
      k = \deg (pq) \leq \deg p + \deg q.
    \end{equation*}

    If \( R \) is an integral domain, the product of nonzero elements is nonzero. Thus the leading coefficient \( \LC(pq) = \LC(p)\LC(q) \) is nonzero and
    \begin{equation*}
      \deg(pq) = \deg p + \deg q.
    \end{equation*}
  \end{description}
\end{proof}

\begin{proposition}\label{thm:polynomial_ring_universal_property}\cite[150]{Knapp2016BAlg}
  For any nontrivial commutative unital ring \( T \), any unital ring homomorphism \( \varphi: R \to T \) and any \( t \in T \), there exists a unique homomorphism \( \Phi_t: R[X] \to T \) such that \( \iota(1) = t \) and the following diagram commutes:

  \begin{AlignedEquation}\label{thm:polynomial_ring_universal_property/diagram}
    \begin{mplibcode}
      beginfig(1);
        input metapost/graphs;

        v1 := thelabel("$R$", origin);
        v2 := thelabel("$R[X]$", (2, 0) scaled u);
        v3 := thelabel("$T$", (1, -1) scaled u);

        a1 := straight_arc(v1, v2);
        a2 := straight_arc(v1, v3);

        d1 := straight_arc(v2, v3);

        draw_vertices(v);
        draw_arcs(a);
        drawarrow d1 dotted;

        label.top("$\iota$", straight_arc_midpoint of a1);
        label.llft("$\varphi$", straight_arc_midpoint of a2);
        label.lrt("$\Phi_t$", straight_arc_midpoint of d1);
      endfig;
    \end{mplibcode}
  \end{AlignedEquation}

  We call the map \( \Phi_t \) a \Def{substitution homomorphism}.

  If \( T \) is a superring of \( R \), we call \( \Phi_t \) an \Def{evaluation} at \( t \in T \). We also write
  \begin{equation}
    R[t] \coloneqq \Phi_t(R[X]).
  \end{equation}

  This allows us to \Def{adjoin} elements from a superring to a subring. See \cref{ex:polynomial_evaluation_gaussian_integers}.
\end{proposition}
\begin{proof}
  We will first prove uniqueness. Let \( \Phi_t: R[X] \to T \) and \( \Psi_t: R[X] \to T \) are two such homomorphisms and take their difference \( \Theta_t \coloneqq \Phi_t - \Psi_t \).

  Then for \( r \in R \) we have
  \begin{equation*}
    \Theta_t(\iota(r)) = \Psi_t(\iota(r)) - \Psi_t(\iota(r)) = \varphi(r) - \varphi(r) = 0.
  \end{equation*}

  Now since for any polynomial we have \( p = \iota(1) p \) and since \( \Theta_t \) is a homomorphism of rings, we have
  \begin{equation*}
    \Theta_t(p) = \Theta_t(\iota(1) p) = 0 \Theta_t(p) = 0.
  \end{equation*}

  Thus \( \Theta_t = 0 \) and \( \Phi_t = \Psi_t \).

  Now we will show existence. Take a polynomial
  \begin{equation*}
    p = (a_0, a_1, \ldots, a_n, 0, 0, \ldots).
  \end{equation*}

  Define
  \begin{equation*}
    \Phi_t(p) \coloneqq \sum_{i=1}^n \phi(a_0) t^i.
  \end{equation*}

  By additivity, \( \Phi_t: R[X] \to T \) is obviously a homomorphism and \( \Phi_t((0, 1, 0, \ldots)) = t \). Therefore we have proven existence.
\end{proof}

\begin{example}\label{ex:polynomial_evaluation_gaussian_integers}
  The Gaussian integers\Tinyref{def:gaussian_integers} \( \Z[i] \) are complex numbers with integer real and complex parts. We will now motivate this notation.

  Consider the substitution map \( \Phi_i: \Z[X] \to \Co \) for the imaginary unit given by \cref{thm:polynomial_ring_universal_property}. Let \( p(X) \in \Z[X] \). Then
  \begin{equation*}
    p(i)
    =
    \Phi_i(p)
    =
    \sum_{j=0}^n a_j i^n
    =
    \sum_{\Rem(j, 4) = 0}^n a_j - \sum_{\Rem(j, 4) = 2}^n a_j + i \left(\sum_{\Rem(j, 4) = 1}^n a_j - \sum_{\Rem(j, 4) = 3}^n a_j \right).
  \end{equation*}

  This is clearly a Gaussian integer.

  Now fix a Gaussian integer \( z = a + bi \). It can given by the polynomial
  \begin{equation*}
    p_z(X) \coloneqq a + bX.
  \end{equation*}

  It remains to show that multiplication in \( \Z[X] \) is compatible with multiplication in \( \Co \). But complex multiplication\Tinyref{def:complex_numbers} is defined to be compatible with the notation \( a + bi \), that is,
  \begin{equation*}
    (a + bi) (c + di)
    =
    ac + ibc + iad - bd
    =
    (ac - bd) + i(bc + ad).
  \end{equation*}

  Thus the Gaussian integers are precisely the homomorphic image of \( Z[X] \) under \( \Phi_i \).
\end{example}

\begin{proposition}\label{thm:polynomial_ring_units}
  The units of the polynomial ring \( R[X] \) are precisely the units of \( R \).
\end{proposition}
\begin{proof}
  Any unit of \( R \) is obviously a unit of \( R[X] \).

  For the converse, fix a nonzero constant polynomial \( p(X) = r \). In order for it to have an inverse \( q(X) \), we should have
  \begin{equation*}
    1 = p(X) q(X) = r q(X),
  \end{equation*}
  which can only happen if \( q(X) \) is a constant and a multiplicative inverse of \( r \).
\end{proof}

\begin{proposition}\label{thm:polynomial_algebra_basis}
  The polynomial algebra\Tinyref{def:algebra_of_polynomials} \( R[X] \) has a Hamel basis\Tinyref{def:left_module_hamel_basis} consisting of all monomials\Tinyref{def:polynomial/monomial}
  \begin{equation*}
    B \coloneqq \{ 1, X, X^2, X^3, \ldots \}.
  \end{equation*}
\end{proposition}
\begin{proof}
  By \cref{def:algebra_of_polynomials/addition}, every polynomial can easily be represented as a sum of finitely many monomials.
\end{proof}

\begin{definition}\label{def:polynomial_free_module}
  It is convenient, especially in approximation theory\Tinyref{sec:approximation_theory}, to work with the free module of polynomials of degree at most \( n \). We define
  \begin{equation*}
    \pi_n(R[X]) \coloneqq \Span \{ 1, X, \ldots, X^{n-1}, X^n \}.
  \end{equation*}
\end{definition}

\begin{proposition}\label{thm:polynomials_over_integral_domain_are_integral_domain}
  If \( R \) is an integral domain, the polynomial ring \( R[X] \) is also an integral domain.
\end{proposition}
\begin{proof}
  Polynomial multiplication inherits its commutativity from multiplication in \( R \). It remains only to show that \( R[X] \) has no zero divisors.

  Fix two polynomials \( p, q \in R[X] \). If either of them is zero, their product \( pq \) is zero.

  Assume that both are nonzero polynomials. The leading coefficient of their product is, by definition of multiplication, \( \LC(pq) = \LC(p) \LC(q) \). Since \( R \) has no zero divisors, then \( \LC(pq) \neq 0 \) and thus \( pq \) is a nonzero polynomial.

  Therefore \( R[X] \) is an integral domain.
\end{proof}

\begin{proposition}\label{thm:polynomials_over_unique_factorization_domain_are_unique_factorization_domain}
  If \( R \) is a unique factorization domain, the polynomial ring \( R[X] \) is also a unique factorization domain.
\end{proposition}

\begin{theorem}[Euclidean division of polynomials]\label{thm:euclidean_division_of_polynomials}\cite[10]{Knapp2016BAlg}
  Let \( a, b \in R[X] \) and \( b \) be monic\Tinyref{def:polynomial/leading_coefficient} (in particular, \( b \neq 0 \)). Then there exist unique polynomials \( q, r \in R[X] \), where \( r \) is either zero or \( \deg r < \deg b \), such that
  \begin{equation*}
    a = bq + r.
  \end{equation*}
\end{theorem}
\begin{proof}
  Let \( a, b \in R[X] \) and \( b \neq 0 \). If \( a = 0 \) or \( \deg a < \deg b \), define
  \begin{align*}
    q &\coloneqq 0, \\
    r &\coloneqq a.
  \end{align*}

  In this case, \( \deg r = \deg a < \deg b \).

  Suppose that \( \deg b \leq \deg a \). We will use proof by induction on \( \deg a \). If \( \deg a = 0 \), obviously \( \deg b = 0 \) (thus \( b = 1 \)) and we define
  \begin{align*}
    q &\coloneqq a, \\
    r &\coloneqq 0.
  \end{align*}

  In this case, \( r \) is the zero polynomial.

  Assume the result holds for \( \deg a < n \) and let \( \deg a = n, \deg b = m \). Then there exists a polynomial \( \hat a(X) \) that is either zero or \( \deg \hat a = n - 1 \) such that
  \begin{equation*}
    a(X) = a_n a^n + \hat a(X).
  \end{equation*}

  Analogously, we find \( \hat b(X) \) that is either zero or \( \deg \hat b = m - 1 \) such that
  \begin{equation*}
    b(X) = X^m + \hat b(X).
  \end{equation*}

  Thus
  \begin{align*}
    \hat r(X)
    &\coloneqq
    a(X) - b(X) a_n X^{n-m}
    = \\ &=
    a_n X^n + \hat a(X) - (b_m X^m + \hat b(X)) a_n X^{n-m}
    = \\ &=
    a_n X^n + \hat a(X) - a_n X^n - \hat b(X) a_n X^{n-m}
    = \\ &=
    \hat a(X) - \hat b(X) a_n X^{n-m}.
  \end{align*}

  Therefore \( \hat r(X) \) is either the zero polynomial (in which case we define \( r(X) \coloneqq \hat r(X) \)) or \( \deg \hat r \leq n - 1 \). In the latter case, we can divide \( \hat r \) by \( b \) to obtain \( \hat q(X) \) and \( r(X) \) such that
  \begin{equation*}
    \hat r(X) \coloneqq b(X) \hat q(X) + r(X),
  \end{equation*}
  where \( r = 0 \) or \( \deg r < \deg b \).

  Substitute into the definition of \( \hat r(X) \):
  \begin{align*}
    \hat r(X) &= a(X) - b(X) a_n X^{n-m} \\
    b(X) \hat q(X) + r(X) &= a(X) - b(X) a_n X^{n-m} \\
    b(X) \left(\hat q(X) - a_n X^{n-m} \right) + r(X) &= a(X).
  \end{align*}

  Define
  \begin{equation*}
    q(X) \coloneqq \hat q(X) - a_n X^{n-m}.
  \end{equation*}

  We have obtained polynomials \( r(X) \) and \( q(X) \) where \( r(X) \) is either zero or \( \deg r < \deg b \).

  It remains only to show uniqueness. Suppose that
  \begin{equation*}
    a = bq + r = bq' + r'.
  \end{equation*}

  If \( r - r' \) is the zero polynomial, so is \( q - q' \) and uniqueness follows.

  If \( r - r' \) is not zero, then neither is \( q - q' \). Then \( b(q - q') = -(r - r') \) and
  \begin{equation*}
    \deg b + \deg(q - q') = \deg[b (q - q')] = \deg(r - r') \leq \max(\deg r, \deg r') < \deg b,
  \end{equation*}
  which is a contradiction.

  This proves uniqueness.
\end{proof}

\begin{corollary}\label{thm:polynomials_over_field_are_euclidean_domain}\cite[10]{Knapp2016BAlg}
  The polynomial ring\Tinyref{def:semiring/integral_domain} \( \K[X] \) over a field \( \K \) is an Euclidean\Tinyref{def:semiring/euclidean_domain} domain with \( \delta(p) \coloneqq \deg p \). Furthermore, the remainder and quotient are unique.
\end{corollary}
\begin{proof}
  By \cref{thm:polynomials_over_integral_domain_are_integral_domain}, \( \K[X] \) is an integral domain.

  To show that it is Euclidean, fix two polynomials \( a, b \in \K[X] \) with \( b \neq 0 \). We use \cref{thm:euclidean_division_of_polynomials} to perform Euclidean division of \( a \) by the monic polynomial \( \frac {b} {\LC(b)} \) and obtain polynomials \( q, r \), where either \( r = 0 \) or \( \deg r < \deg b \), such that
  \begin{equation*}
    a = \frac {b} {\LC(b)} q + r.
  \end{equation*}

  Instead of dividing \( b \) by its leading coefficient \( \LC(b) \), we can divide \( q \) and thus obtain the required factorization.
\end{proof}

\begin{definition}\label{def:polynomial_function}
  Let \( \End(R) \) be the endomorphism ring\Tinyref{def:endomorphism_semiring} over \( R \). Define the unital ring homomorphism
  \begin{align*}
    &\Phi: R[X] \to \End(R) \\
    &\Phi((a_0, a_1, \ldots, a_n, 0, 0, \ldots)) \coloneqq \left( x \to \sum_{i=0}^n a_i x^n \right),
  \end{align*}
  which constructs a \Def{polynomial function} from a polynomial. This map is not injective in general and multiple polynomials may be equivalent as functions\Tinyref{def:function}.

  If we want to highlight that we are referring to a polynomial function rather than a polynomial \( p(X) \), we use a lowercase letter for the variable, i.e.
  \begin{equation*}
    p(x) = \sum_{i=0}^n a_i x^i.
  \end{equation*}
\end{definition}
\begin{proof}
  This is indeed a homomorphism. We will only prove that multiplication of polynomials corresponds to multiplication of polynomial functions because the rest is obvious.
  \begin{align*}
    p(X) &\coloneqq \sum_{i=0}^n a_i X^i, \\
    q(X) &\coloneqq \sum_{j=0}^m b_j X^j.
  \end{align*}

  For their product \( s(X) = \sum_{i=0}^{n + m} c_i X^i \) by definition we have
  \begin{equation*}
    c_l = \sum_{i+j=l} a_i b_j, l = 0, 1, \ldots, n + m.
  \end{equation*}

  We need to show that for any \( r \in R \)
  \begin{equation*}
    p(r) q(r) = s(r).
  \end{equation*}

  Using associativity and commutativity of multiplication and distributivity of multiplication over addition, we obtain
  \begin{align*}
    p(r) q(r)
    &=
    \left( \sum_{i=0}^n a_i r^i \right) \left( \sum_{j=0}^m b_j r^j \right)
    = \\ &=
    \sum_{i=0}^n a_i r^i \left( \sum_{j=0}^m b_j r^j \right)
    = \\ &=
    \sum_{i=0}^n a_i r^i \left( \sum_{j=0}^m b_j r^j \right)
    = \\ &=
    \sum_{i=0}^n \sum_{j=0}^m a_i r^i b_j r^j
    = \\ &=
    \sum_{i=0}^n \sum_{j=0}^m a_i b_j r^{i + j}
    = \\ &=
    \sum_{l=0}^{n + m} \sum_{i+j=l} a_i b_j r^l
    = \\ &=
    \sum_{l=0}^{n + m} c_l r^l
    =
    s(r),
  \end{align*}
  where we have used that \( a_i = 0, i > n \) and \( b_j = 0, j > m \).
\end{proof}

\begin{definition}\label{def:formal_power_series}
  If we extend \cref{def:polynomial} to allow for polynomial with infinite terms (that is, allow for the sequence to have infinitely many nonzero items), we obtain a set \( R[[X]] \) which we call the \Def{formal power series} over \( R \).

  Note that the operations in \cref{def:algebra_of_polynomials} are well defined and still make \( R[[X]] \) into an algebra. Evaluation (see \cref{thm:polynomial_ring_universal_property} and \cref{def:polynomial_function}) is problematic, however, since algebraic operations are finitary by nature. In practice, we use a topology over \( R \) and speak of convergent and divergent power series.
\end{definition}

\begin{theorem}[Newton's binomial theorem]\label{thm:binomial_theorem}
  \begin{equation*}
    (X + Y)^n = \sum_{k=0}^n \binom n k X^k Y^{n-k}
  \end{equation*}
\end{theorem}
\begin{proof}
  We use induction on \( n \). For \( n = 0 \), the theorem trivially holds. Assume that the theorem holds for \( 1, \ldots, n \). Then
  \begin{align*}
    (X + Y)^{n+1}
    &=
    X (X + Y)^n + Y (X + Y)^n
    = \\ &=
    \sum_{k=0}^n \binom n k X^{k+1} Y^{n-k} + Y \sum_{k=0}^n \binom n k X^k Y^{n-k}
    = \\ &=
    X^{n+1} + Y \sum_{k=0}^{n-1} \binom n k X^{k+1} Y^{n-(k+1)} + Y \sum_{k=0}^n \binom n k X^k Y^{n-k}
    = \\ &=
    X^{n+1} + Y \left[ \sum_{k=1}^n \binom n {k-1} X^k Y^{n-k} + Y^n \sum_{k=1}^n \binom n k X^k Y^{n-k} \right] + Y^{n+1}
    = \\ &\overset {\ref{thm:pascals_identity}} =
    X^{n+1} + Y \sum_{k=1}^n \binom {n+1} k X^k Y^{n-k} + Y^{n+1}
    = \\ &=
    \sum_{k=0}^n \binom {n+1} k X^k Y^{(n+1)-k}.
  \end{align*}
\end{proof}

\begin{proposition}\label{thm:polynomial_root_iff_divisible}
  The value \( u \in R \) is a root\Tinyref{def:semiring_kernel} of the polynomial function \( p(x) \) if any only if the polynomial \( (X - u) \) divides \( p(X) \).
\end{proposition}
\begin{proof}
  \begin{description}
    \Implies Suppose that \( u \in R \) is a root of \( p(x) \). By \cref{thm:euclidean_division_of_polynomials}, we can divide \( p(X) \) by the monic polynomial \( (X - u) \):
    \begin{equation*}
      p(X) = (X - u) q(X) + r(X).
    \end{equation*}

    Assume\LEM that \( r(X) \) is nonzero. Evaluating \( p(X) \) at \( u \) gives us
    \begin{equation*}
      0 = p(u) = (u - u) q(r) + r(u),
    \end{equation*}
    hence \( u \) is a root of \( r(X) \). But \( \deg r < \deg (X - u) = 1 \), that is, \( r \) is a nonzero constant and cannot have roots. The obtained contradiction proves the statement.

    \ImpliedBy Suppose that \( (X - u) \) divides \( p(X) \) with quotient \( q(X) \). Then
    \begin{equation*}
      p(X) = (X - u) q(X).
    \end{equation*}

    Evaluation at \( u \) gives us
    \begin{equation*}
      p(u) = (u - u) q(u) = 0.
    \end{equation*}

    Therefore \( u \) is a root of \( p(X) \).
  \end{description}
\end{proof}

\begin{definition}\label{def:polynomial_root_multiplicity}
  We say that the polynomial \( p \in R[X] \) has the root \( r \in R \) with multiplicity \( m \in \Z^{>0} \) if there exists a polynomial \( q \in R[X] \) of degree \( \deg q = \deg p - m \) such that \( (X - r) \) does not divide \( q(X) \) and
  \begin{equation*}
    p(X) = (X - r)^m q(X).
  \end{equation*}
\end{definition}

\begin{proposition}\label{thm:integral_domain_polynomial_root_limit}
  If \( R \) is an integral domain, a nonzero polynomial of degree \( n \) has at most \( n \) (not necessarily distinct\Tinyref{def:polynomial_root_multiplicity}) roots.
\end{proposition}
\begin{proof}
  We will use induction on \( n \).

  In the case \( n = 0 \), we have that \( p \) is a nonzero constant polynomial. Such a polynomial cannot\LEM have roots, hence the statement holds.

  Now assume that the statement holds for polynomials of degrees \( 1, \ldots, n - 1 \). Let \( p \in R[X] \) be a polynomial of degree \( n \) and let \( r \in R \) be a root of \( p \). \Cref{thm:polynomial_root_iff_divisible} implies that there exists a polynomial \( q(X) \) of degree \( n - 1 \) such that
  \begin{equation*}
    p(X) = (X - r) q(X).
  \end{equation*}

  Fix \( t \neq r \) that is a not a root of \( q(X) \). Evaluation at \( t \) gives us
  \begin{equation*}
    p(t) = (t - r) q(t).
  \end{equation*}

  Both \( (t - r) \neq 0 \) and \( q(t) \neq 0 \). Since \( R \) has no zero divisors, the product \( p(t) \) of \( (t - r) \) and \( q(t) \) is also nonzero. Thus the only roots of \( p(X) \) are \( r \) and the roots of \( q(X) \).

  By the induction hypothesis, \( q(X) \) has at most \( n - 1 \) roots (counting multiplicities). Thus \( p(X) \) has at most \( (n - 1) + 1 = n \) roots.
\end{proof}

\begin{proposition}\label{thm:polynomials_with_identical_roots}
  If \( R \) is an integral domain, two polynomials \( p, q \in R[X] \) of the same degree \( n \) are equal if and only if their functions match at \( n + 1 \) points.
\end{proposition}
\begin{proof}
  Define \( r \coloneqq p - q \). This is a polynomial of degree at most \( n \) that has \( n + 1 \) roots. By \cref{thm:integral_domain_polynomial_root_limit}, \( r \) is the zero polynomial. Hence \( p = q \).
\end{proof}

\begin{definition}\label{def:primitive_polynomial}\cite[394]{Knapp2016BAlg}
  A nonzero polynomial is called \Def{primitive} if its coefficients are coprime\Tinyref{def:coprime_ring_ideals}.
\end{definition}

\begin{proposition}\label{thm:polynomial_quotient_rings_equinumerous_with_module_of_polynomials}
  Fix a monic polynomial \( p(X) \in R[X] \) of degree \( n \). The free module \( \pi_n(R[X]) \), as defined in \cref{def:polynomial_free_module}, is equinumerous\Tinyref{def:equinumerous_sets} with the quotient ring \( R[X] / \Gen{p(X)} \). This allows us to choose a \enquote{canonical representative} of the cosets of the quotient ring in a similar manner to \cref{thm:cyclic_group_isomorphic_to_integers_modulo_n}.

  Consequently, for different polynomials \( p(X) \), only the ring structure on \( R[X] / \Gen{p(X)} \) differs.
\end{proposition}
\begin{proof}
  Euclidean division\Tinyref{thm:euclidean_division_of_polynomials} allows us to define the homomorphism
  \begin{align*}
    &\Theta: R[X] / \Gen{p(X)} \to \pi_n(R[X]) \\
    &\Theta(q(X) + \Gen{p(X)}) \coloneqq \Rem(q(X), p(X)).
  \end{align*}

  It is injective since if \( q_1(X) \) and \( q_2(X) \) are not congruent modulo \( \Gen{p(X)} \), they have different remainders. Conversely, \( \Theta \) is surjective because any remainder \( r(X) \) belongs to the coset
  \begin{equation*}
    r(X) + \Gen{p(X)}.
  \end{equation*}

  See \cref{ex:polynomial_quotient_rings_gaussian_integers} and \cref{ex:polynomial_quotient_rings_z2} for differing ring structures in \( \pi_n(R[X]) \).
\end{proof}

\begin{example}\label{ex:polynomial_quotient_rings_gaussian_integers}
  The value of \cref{thm:polynomial_quotient_rings_equinumerous_with_module_of_polynomials} is in that, like \cref{thm:integers_modulo_isomorphic_to_quotient_group}, it allows us to identify elements of the quotient rings of the form \( R[X] / \Gen{p(X)} \), for monic \( p \), with concrete polynomials.

  \Cref{thm:polynomial_quotient_rings_equinumerous_with_module_of_polynomials} tells us that we can choose a concrete polynomial from \( \pi_n(R[X]) \) for every equivalence class in \( R[X] / \Gen{p(X)} \) and that these polynomials have degree strictly less than \( n \) (if they are not zero).

  For example, consider the polynomial \( p(X) \coloneqq X^2 + 1 \) over the integers\Tinyref{def:integers} \( \Z \). It has degree \( 2 \), so the quotient ring \( R[X] / \Gen{p(X)} \) can be identified with polynomials of the form
  \begin{equation}\label{ex:polynomial_quotient_rings_gaussian_integers/linear_polynomial}
    aX + b
  \end{equation}
  with integer coefficients.

  In order to make sense of the imposed ring structure in \( \Z[X] / \Gen{X^2 + 1} \), we can see how multiplication modulo \( X^2 + 1 \) works. We have
  \begin{align*}
    (aX + b) (cX + d)
    &\equiv
    acX^2 + (bc + ad)X + bd
    &\pmod {X^2 + 1} \equiv \\ &\equiv
    ac[X^2 + 1] + [(bc + ad)X - ac + bd]
    &\pmod {X^2 + 1} \equiv \\ &\equiv
    (bc + ad)X + (bd - ac)
    &\pmod {X^2 + 1}. \phantom{\equiv}
  \end{align*}

  This is precisely the definition of multiplication of complex numbers (see \cref{def:complex_numbers}) (except that we may need to swap \( a \) with \( b \) and \( c \) with \( d \)). Thus we can identify
  \begin{equation*}
    \Z[X] / \Gen{X^2 + 1} \cong \Z[i].
  \end{equation*}

  Like in \cref{ex:polynomial_evaluation_gaussian_integers}, we arrive at the Gaussian integers\Tinyref{def:gaussian_integers}, but using a different approach.
\end{example}

\begin{example}\label{ex:polynomial_quotient_rings_z2}
  Similarly to how the Gaussian integers were identified using \cref{ex:polynomial_quotient_rings_gaussian_integers}, we will provide a different ring structure on \( \Z[X] / \Gen{p(X)} \) for a polynomial \( p(X) \) of degree \( 2 \).

  Consider the polynomial \( p(X) \coloneqq X^2 - 2 \) over the integers\Tinyref{def:integers} \( \Z \). We know that \( \sqrt 2 \) is a root of \( X^2 - 2 \) in \( \R \) so we can identify
  \begin{equation*}
    \Z[X] / \Gen{X^2 - 2} \cong \Z[\sqrt 2].
  \end{equation*}

  We will verify that multiplication is indeed compatible. Multiplication modulo \( X^2 - 2 \) works as follows:
  \begin{align*}
    (aX + b) (cX + bd)
    &\equiv
    acX^2 + (bc + ad)X + bd
    &\pmod X^2 - 2 \equiv \\ &\equiv
    ac[X^2 - 2] + [(bc + ad)X + 2ac + bd]
    &\pmod X^2 - 2 \equiv \\ &\equiv
    (bc + ad)X + (2ac + bd)
    &\pmod X^2 - 2. \phantom{\equiv}
  \end{align*}

  Multiplication in \( \Z[\sqrt 2] \) works as follows:
  \begin{align*}
    (a \sqrt 2 + b) (c \sqrt b + d)
    =
    2ac + (bc + ad) \sqrt 2 + bd.
  \end{align*}

  The two results are identical.
\end{example}

\begin{definition}\label{def:algebraic_derivative}
  Generalizing \cref{def:derivatives} from analysis, we define the \Def{algebraic derivative} of a polynomial \( p(X) \in R[X] \) as
  \begin{equation*}
    p'(X) \coloneqq n a_n X^{n-1} + (n-1) a_{n-1} X^{n-2} + \cdots + a_2 X + a_1.
  \end{equation*}
\end{definition}

\begin{proposition}\label{thm:algebraic_derivative_product_rule}
  Algebraic derivatives\Tinyref{def:algebraic_derivative} satisfy the product rule
  \begin{equation*}
    (pq)' = p'q + pq'.
  \end{equation*}
\end{proposition}
\begin{proof}
  By linearity, it is enough to consider the case where both \( p(X) \) and \( q(X) \) are monomials.

  \begin{align*}
    p'(X) q(X) + p(X) q'(X)
    &=
    n a_n X^{n-1} b_m X^m + a_n X^n m b_m X^{m-1}
    = \\ &=
    (n + m) a_n b_m X^{n+m-1}
    = \\ &=
    (a_n b_m X^{n+m})
    = \\ &=
    (pq)'(X).
  \end{align*}
\end{proof}

\begin{proposition}\label{thm:algebraic_derivative_of_linear_polynomial_power}
  The algebraic derivative\Tinyref{def:algebraic_derivative} of
  \begin{equation*}
    p(X) \coloneqq a (X - u)^n
  \end{equation*}
  is
  \begin{equation*}
    p'(X) = an(X - u)^{n-1}.
  \end{equation*}
\end{proposition}
\begin{proof}
  We use induction on \( n \). The case \( n = 1 \) is obvious. Assume that the statement holds for \( 1, \ldots, n - 1 \).

  By \cref{thm:algebraic_derivative_product_rule},
  \begin{align*}
    p'(X)
    &=
    [a(X - u)^{n-1}]' (X - u) + a(X - u)^{n-1} [(X - u)]'
    = \\ &=
    a(n-1)(X - u)^{n-2} (X - u) + a(X - u)^{n-1}
    = \\ &=
    an(X - u)^{n-1}.
  \end{align*}
\end{proof}

\begin{corollary}\label{thm:repeated_root_iff_derivatives_divisible}
  The value \( u \in R \) is a root\Tinyref{def:semiring_kernel} of multiplicity \( m \) of the polynomial function \( p(x) \) if any only if \( u \) is a root of multiplicity \( m - 1 \) of its algebraic derivative\Tinyref{def:algebraic_derivative} \( p'(x) \).
\end{corollary}
\begin{proof}
  \begin{description}
    \Implies Let \( u \) be a root of \( p(X) \) of multiplicity \( m \), i.e. there exists a polynomial \( q(X) \) of degree \( \deg(q) = \deg(p) - m \) such that \( (X - u) \) does not divide \( q(X) \) and
    \begin{equation*}
      p(X) = (X - u)^m q(X).
    \end{equation*}

    By \cref{thm:algebraic_derivative_product_rule} and \cref{thm:algebraic_derivative_of_linear_polynomial_power},
    \begin{equation*}
      p'(X)
      =
      m (X - u)^{m-1} q(X) + (X - u)^m q'(X)
      =
      (X - u)^{m-1} [m q(X) + (X - u) q'(X)].
    \end{equation*}

    Then \( u \) is a root of \( p'(X) \) of multiplicity at least \( m - 1 \). Assume\LEM that the multiplicity is at least \( m \), that is,
    \begin{equation*}
      (X - u) \mid [mq(X) + (X - u) q'(X)].
    \end{equation*}

    Since \( X - u \) obviously divides \( (X - u) q'(X) \), then the above implies
    \begin{equation*}
      (X - u) \mid mq(X).
    \end{equation*}

    But this contradicts our choice of \( q(X) \) that does not divide \( (X - u) \).

    The obtained contradiction proves that \( u \) if a root of \( p'(X) \) of multiplicity exactly \( n \).
  \end{description}
\end{proof}

\begin{definition}\label{def:multivariate_polynomial}
  We define the \Def{multivariate polynomial ring} in \( k \) indeterminates as the \enquote{iterated} single-variable polynomial ring
  \begin{equation*}
    R[X_1, X_2, \ldots, X_k] \coloneqq R[X_1][X_2] \cdots [X_k].
  \end{equation*}

  Each polynomial \( p(X_1, \ldots, X_k) \) is an \( k \)-dimensional array\Tinyref{def:array} over \( R \). If there are only two variables, multivariate polynomials are matrices
  \begin{equation*}
    p(X_1, X_2) \coloneqq \begin{pmatrix}
      a_{0,0} & a_{0,1} & \cdots \\
      a_{1,0} & a_{1,1} & \cdots \\
      \vdots  & \vdots  & \ddots \\
    \end{pmatrix}
  \end{equation*}
  with only finitely many nonzero elements.

  A \Def{monomial} is a polynomial with only one nonzero element. The monomial
  \begin{equation*}
    p(X_1, X_2) \coloneqq \begin{pmatrix}
      0       & 0       & 0       & \cdots \\
      0       & 0       & 0       & \cdots \\
      0       & r       & 0       & \cdots \\
      0       & 0       & 0       & \cdots \\
      \vdots  & \vdots  & \vdots  & \ddots \\
    \end{pmatrix}
  \end{equation*}
  can also be written symbolically as \( p(X_1, X_2) = r X_1^2 X_2 \), with the power for each variable corresponding to the zero-based index of the element along the corresponding axis.

  The sum of the indices over all axes is called the \Def{degree} of this monomial. The above monomial has degree \( 3 = 2 + 1 \). We leave the degree for the zero monomial undefined.

  Every polynomial can be regarded as the sum of finitely many monomials by taking each element of the array and putting it in its own monomial array.

  The \Def{degree} \( \deg p \) of a multivariate polynomial \( p \) is defined as the maximal degree among all of its nonzero monomials. If all monomials are zero, the degree is left undefined.

  If all nonzero monomials have the same degree, the polynomial is said to be \Def{homogeneous}.
\end{definition}

\begin{definition}\label{def:rational_algebraic_function}
  We denote the field of fractions\Tinyref{def:field_of_fractions} of \( R[X_1, \ldots, X_k] \) by \( R(X_1, \ldots, X_k) \) and call it the field of \Def{rational algebraic functions}.
\end{definition}
