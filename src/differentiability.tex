\subsection{Differentiability}\label{subsec:differentiability}

Let \( X \) and \( Y \) be Hausdorff topological vector spaces\Tinyref{def:topological_vector_space} and let \( U \subseteq X \) be an open set.

\begin{definition}\label{def:differentiability}
  Out goal is to study the following partial\Tinyref{def:function/partial} operator:
  \begin{align}\label{def:differentiability/partial_operator}
    &D: \Cat{Set}(U, Y) \times U \times X \to Y \\
    &D(f, x, h) \coloneqq \lim_{t \downarrow 0} \frac {f(x + th) - f(x)} t.
  \end{align}

  We implicitly assume that \( t \neq 0 \) because otherwise the definition would not make sense.

  Note that the operator \( D \) is defined slightly differently in the rest of the document. See \cref{remark:derivative_notation} for a discussion of derivative notation.

  The quotient under the limit sign is called a \Def{difference quotient}.

  For each function \( f: U \to Y \), each point \( x_0 \in X \) and each \enquote{direction} vector \( x_0 \in X \), we want to obtain a value in \( Y \), which we will call the \Def{directional derivative} of \( f \) at \( x_0 \) in the direction \( h \).

  The existence of a directional derivative is already a harsh condition, however we impose even harsher restrictions

  \begin{defenum}
    \DItem{def:differentiability/first_variation}\cite[section 0.2.1]{Йоффе1974} If, for fixed \( f \) and \( x_0 \), the directional derivative \( D(f, x_0, h) \) exists for all directions \( h \), we define the \Def{first variation} of \( f \) at \( x_0 \) as
    \begin{align*}
      &\delta f(x_0): X \to Y \\
      &[\delta f(x_0)](h) \coloneqq D(f, x_0, h).
    \end{align*}

    Within its domain of definition of \( \delta \), which is stricter than that of \( D \), the operator \( \delta \) is a currying\Tinyref{def:function_arguments} of \( D \).

    Note that, in general, the first variation operator \( \delta f(x_0) \) is not linear - for example, by \cref{thm:convex_one_sided_derivatives_sublinear}, the first variation of a general convex functions is, at most, sublinear. See \fullref{sec:nonsmooth_analysis} for how \enquote{nonlinear derivatives} are handled.

    \DItem{def:differentiability/gateaux}\cite[section 0.2.1]{Йоффе1974} If the first variation \( \delta f(x_0) \) is a continuous linear operator, we say that \( f \) is \Def{Gateaux differentiable} or \Def{weakly differentiable} at \( x_0 \) with \Def{Gateaux derivative} \( f'_G(x_0) \coloneqq \delta f(x_0) \).

    \DItem{def:differentiability/frechet}\cite[section 0.2.1]{Йоффе1974} We now restrict our attention to Banach spaces\Tinyref{def:banach_space}. We say that \( f \) is \Def{Frechet differentiable} or \Def{strongly differentiable} at \( x_0 \) if there exists a continuous linear operator \( f'(x_0): X \to Y \), called the \Def{Frechet derivative} of \( f \) at \( x_0 \), such that
    \begin{equation}\label{def:differentiability/frechet/condition}
      \lim_{h \to 0} \frac {\Norm{f(x_0 + h) - f(x_0) - \Prod{f'(x_0)} h}_Y} {\Norm{h}_X} = 0.
    \end{equation}

    We discuss in \cref{remark:gateaux_vs_frechet} how Frechet differentiability is a special case of Gateaux differentiability.

    \DItem{def:differentiability/strict}\cite[33]{Dontchev2014} An even stronger condition than that of Frechet differentiability is \Def{strict differentiability}. We say that \( f \) is \Def{strictly differentiable} at \( x_0 \) if there exists a continuous linear operator \( f'(x_0): X \to Y \), called the \Def{strict derivative} of \( f \) at \( x_0 \), such that
    \begin{equation}\label{def:differentiability/strict/condition}
      \lim_{\substack{y \to x_0 \\ z \to x_0}} \frac {\Norm{f(y) - f(z) - \Prod{f'(x_0)} {y - z}}_Y} {\Norm{y - z}_X} = 0.
    \end{equation}
  \end{defenum}
\end{definition}

\begin{remark}\label{remark:derivative_notation}
  We will not be using the operators \( D \) and \( \delta \) as defined in \cref{def:differentiability}. The following are standard notations for derivatives (taken from \cite[146]{Фихтенгольц1968/2}):
  \begin{remenum}
    \DItem{remark:derivative_notation/lagrange} We already used \Def{Lagrange's notation} \( f'(x_0) \) and \( f_G'(x_0) \) in \cref{def:differentiability}. Brevity is the only benefit of this notation. It becomes convenient when the functions have no name is a burden for directional derivatives.

    The second and third derivatives of \( f \) at \( x_0 \) are denoted as \( f^{''}(x_0) \) and \( f^{'''}(x_0) \) and the \( n \)-th derivative of is denoted as \( f^{(n)} \).

    See \cref{def:nonsmooth_derivatives} for variations of this notation.

    \DItem{remark:derivative_notation/newton} Newton's notation is similar to that of Leibniz but depends on placing dots on top of \( f \), e.g. \( \ddot{f}(x_0) \coloneqq f''(x_0) \). This is used in areas like mathematical physics, however it has not become standard in more pure areas of analysis.

    \DItem{remark:derivative_notation/euler} We use \Def{Euler's notation} \( Df(x_0) \coloneqq f'(x_0) \) for more complicated expressions, e.g. \cref{thm:derivative_limit_exchange}. The main benefit of this notation is that is allows to express differentiation as an operator, similar to what we defined in \cref{def:differentiability}. The directional derivative of \( f \) at \( x_0 \) in the direction \( h \) is denoted as \( D_h f(x_0) \). Iterated differentiation corresponds to the standard notation for group composition: the \( n \)-th derivative at \( x_0 \) is denoted as \( D^n f(x_0) \).

    We also use other letters in the superscripts like \( D^G f(x_0) \) for Gateaux derivatives, \( D^\circ f(x_0) \) for Clarke's generalized derivatives, etc.

    \DItem{remark:derivative_notation/phelps} Some authors like \cite{Phelps1993} use a variation of Euler's notation with \( \partial \) instead of \( D \). For example, directional derivatives are introduced as \( \partial^+ f(x_0)(h) \) in \cite[lemma 1.2]{Phelps1993}. This is consistent with the standard notation for subdifferentials - see \cref{def:subdifferentials}, however Euler's notation appears to be more widely adoped.

    \DItem{remark:derivative_notation/leibniz} The Leibniz notation for the derivative \( f'(x_0) \) is
    \begin{equation*}
      \frac {df} {dx} (x_0) \coloneqq D f(x_0).
    \end{equation*}

    This notation is used extensively in integral calculus, however it is often confusing when manipulating derivatives. The fraction notation is unjustified in anything but trivial cases and the partial derivative notation
    \begin{equation*}
      \frac {\partial f} {\partial x} (x_0) \coloneqq D_x f(x_0)
    \end{equation*}
    is even more confusing.

   Note also that this depends on the convention of having named variable names\Tinyref{def:function_arguments}.
  \end{remenum}
\end{remark}

\begin{remark}\label{remark:gateaux_vs_frechet}
  We will compare Gateaux differentiability\Tinyref{def:differentiability/gateaux} with Frechet differentiability \Tinyref{def:differentiability/frechet}. Let \( X \) and \( Y \) be Banach spaces, let \( U \subseteq X \) be an open set and let \( f: U \to Y \) be an arbitrary function. Fix a point \( x_0 \in U \).

  The continuous linear operator \( \Lambda: X \to Y \) is a Gateaux derivative if, for every \( \varepsilon_G > 0 \) and every direction \( h \in X \) there exists \( \delta_G^h > 0 \) such that
  \begin{equation}\label{remark:gateaux_vs_frechet/gateaux_step1}
    \Norm{\frac {f(x_0 + th) - f(x_0)} t - \Prod \Lambda h}_Y < \varepsilon_F \quad\forall t \in (0, \delta_G^h).
  \end{equation}

  In order for \( \Lambda \) to be a Frechet derivative, for every \( \varepsilon_F > 0 \) there must exist a single \( \delta_F > 0 \) so that
  \begin{equation}\label{remark:gateaux_vs_frechet/frechet_step1}
    \frac{\Norm{f(x_0 + h) - f(x_0) - \Prod \Lambda h}_Y} {\Norm{h}_X} < \varepsilon_F \quad\forall h \in B(0, \delta_F).
  \end{equation}

  This can be restated as
  \begin{equation}\label{remark:gateaux_vs_frechet/frechet_step2}
    \Norm{\frac {f(x_0 + h) - f(x_0)} {\Norm{h}_X} - \Prod \Lambda {\frac {h} {\Norm{h}_X}}}_Y < \varepsilon_F \quad\forall h \in B(0, \delta_F).
  \end{equation}

  Every \( h \in X \) can be represented as \( t k \), where \( t = \Norm{h}_X \) and \( k = \tfrac 1 t h \). Conversely, given \( k \in S_X \) and \( t \geq 0 \), we can cover all of \( X \). Therefore \cref{remark:gateaux_vs_frechet/frechet_step2} can be rewritten as
  \begin{equation}\label{remark:gateaux_vs_frechet/frechet_step3}
    \Norm{\frac {f(x_0 + tk) - f(x_0)} t - \Prod \Lambda k}_Y < \varepsilon_F \quad\forall t \in (0, \delta_F) \ \forall k \in S_X.
  \end{equation}

  Note that \cref{remark:gateaux_vs_frechet/gateaux_step1} and \cref{remark:gateaux_vs_frechet/frechet_step2} are equivalent except that \( \delta_G^h \) depends on \( h \) and \( \delta_F \) does not.

  Therefore \cref{def:differentiability/frechet} can be restated as: the function \( f \) is Frechet differentiable at \( x_0 \) if it is Gateaux differentiable and the convergence of the Gateaux derivative is uniform on \( h \in S_X \).

  In particular, Frechet differentiability implies Gateaux differentiability.
\end{remark}
